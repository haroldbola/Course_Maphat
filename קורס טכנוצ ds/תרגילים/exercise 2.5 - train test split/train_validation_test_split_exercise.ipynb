{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train-test split exercise.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"c3bcNQ5zu9b7","colab_type":"text"},"cell_type":"markdown","source":["## The Importance of the Train-Validation-Test Split\n","```In this exercise you will experience with an importent and often neglected issue in the data scienstist's work: the train-validation-test split. We will work with a specific dataset and we will see that the naïve method for splitting does not yield good results. We will examine different splitting methods that take into consideration the structure of the dataset, and consequently yield better results.```\n","\n","```~ Ittai Haran```"]},{"metadata":{"id":"Q0WDtBNMu9b_","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VA-4furhu9cF","colab_type":"text"},"cell_type":"markdown","source":["```First, load the dataset, given to you as data.csv, using pandas. (Note that you are also given a separate dataset - the file data_test.csv - that we will use later for testing)```\n","\n","```Take a moment to explore the dataset. Notice that the dataset is made out of pairs of objects: each row has two ids, one for each object in the pair (the objects are labeled 'left' and 'right'). The features related to each object are also included in each row. Finally, in each row we have a target that we would like to predict.```\n","\n","```How many different objects are there?```\n","\n","```We would like to describe the objects and the data using an appropriate data structure. Which data structure can best describe this dataset?```\n"]},{"metadata":{"id":"yeYw5N1Eu9cH","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"fOtcof2Au9cO","colab_type":"text"},"cell_type":"markdown","source":["```You will now use a library called networkx. This library is used for manipulating graphs in python. Use it to create a graph from the pandas dataset you just loaded.```\n","\n","```How many connected components does the graph have? Draw a histogram of their sizes (use networkx).```\n","\n","``` Are there any edges that aren't between left objects and right objects? That kind of graph is called a bipartite graph.```"]},{"metadata":{"id":"OqpzcV7Au9cQ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UPB_w6MEu9cX","colab_type":"text"},"cell_type":"markdown","source":["```In order to create a baseline model we will try to make predictions using only one object from each row.```\n","\n","```Create a dataset containig only the features of the left objects. Drop duplicates, so that every object will appear only once.```"]},{"metadata":{"id":"gWtT-ZIFmhqn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"c4c-g02_u9ch","colab_type":"text"},"cell_type":"markdown","source":["```We will now use the regular, naïve, splitting method. Split your data randomly with ratio 0.7-0.3 to train and validation segments. Train a simple model (a random forest for example) to predict the target. Make sure your model isn't overfitted, and try to get the best score you can (on the validation segment). Compare your results to a simple baseline - the mean of the target computed on the train segment.```"]},{"metadata":{"id":"0GGXf12Qu9cj","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ItESli1eu9cx","colab_type":"text"},"cell_type":"markdown","source":["```Use the model you got to compute loss on the separate test dataset given to you (data_test.csv). Did you get similar results for the validation and test segments?```"]},{"metadata":{"id":"6B-mF-m0u9cz","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"OzJyv8Osu9c_","colab_type":"text"},"cell_type":"markdown","source":["```Repeat that process, only this time use all features, and not just those of the left objects. Accordingly, you don't have to drop any duplicates. Again, use the naïve splitting method.```\n","\n","```Did you get a good score on both train and validation? why (or why not)?```\n","\n","```Do you think the score you got on the validation corresponds to the \"real\" error? Compute the loss on the separated test segment to get the \"real\" error. Is there any gap between validation-error and test-error? Why?```"]},{"metadata":{"id":"hREu48P_u9dE","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"1E1RkQ-Tu9dQ","colab_type":"text"},"cell_type":"markdown","source":["```We will now use a different splitting method. In this method, every connected component is contained either in the train segment or in the test segment. To do so, implement the following algorithm (use networkx):```\n","\n","```while length(train_segment) < 0.7 * length(data):```\n","```\n","    randomly choose a row r (an edge in the graph) from the data, that is not in train_segment\n","    add the connected component containing r to the train_segment.```\n","    \n","```validation_segment = data - train_segment```\n","\n","*```Useful networkx functions: set_edge_attributes, connected_component_subgraphs```*"]},{"metadata":{"id":"elJiJvoJu9dS","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"tXOuHFOhu9dX","colab_type":"text"},"cell_type":"markdown","source":["```Train a model using your new train segment.```\n","\n","```What is the best score you can get on your validation segment? Compare it to the test segment. ```\n","\n","```What is the problem with this new splitting method that we used? Hint: How many connected components are there in the train segment, and how many are in the validation segment? Compare the distribution of the value of the target, in the train segment and in the validation segment (you can create a histogram). Do they look the same? ```\n","\n","```Can we safely use this validation error to estimate the error on the test segment?```"]},{"metadata":{"id":"ShuqhAILu9da","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"akVhbS03vBuF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YhpHvYdEu9dh","colab_type":"text"},"cell_type":"markdown","source":["```We will now try a third method for splitting the dataset. This time make sure you have around 70% of the connected components in your train segment. That is, implement the following algorithm:```\n","\n","```while length(train_segment) < 0.7 * length(data):```\n","```\n","    randomly choose a connected component c from the graph\n","    add c to the train_segment\n","```\n","\n","```validation_segment = data - train_segment```"]},{"metadata":{"id":"r5CBlJd8u9di","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xf_ynT94u9dn","colab_type":"text"},"cell_type":"markdown","source":["```What part of the connected components do you have in your train segment this time? Look again at the distribution of the target in the two segments (train and validation).```"]},{"metadata":{"id":"02ljunTvu9dq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hwj9PjVFu9dw","colab_type":"text"},"cell_type":"markdown","source":["```Train a model using the new train segment.```\n","\n","```What is the best score you can get on your validation and test segments? Did you get a better score? Can you now use the validation segment to estimate the real error? ```"]},{"metadata":{"id":"QO4o-qdQu9dy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"66xab56Cu9d1","colab_type":"text"},"cell_type":"markdown","source":["```Bonus: the data for this exercise was uniquely generated, using MNIST (what? how???). Can you generate a similar dataset? What parameters control this problem? Explain how it can be done.```"]},{"metadata":{"id":"TmnbLuGJu9d3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}