{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Good morning, gent!\n",
    "The year is 1945. The British forces are about to wipe out the Nazis, once and for all.\n",
    "You are a young enthusiast meteorologist, and you are about to give the Great British Empire its victory!\n",
    "At your disposal is the Royal Dataset of Measurements from forecasting stations around the globe. Measurements are taken each morning and each noon. Since we are British, we don't believe in surprise attacks. Leave that rubbish for the barbarians. Instead, we spend each morning preparing for the battle, and attack the bloody Nazis by noon, like gentlemen. Hence, it is of utter importance that you can forecast the temperatures at noon each day.\n",
    "Are you ready for the mission? Are you ready to destroy the Nazis?```\n",
    "\n",
    "```~Ittai Haran```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Start by reading the Royal Dataset of Measurements. Also at your disposal is the data_weather_station_locations dataset. As a former meteorologist myself, I suggest you merge it into your measurements dataset.\n",
    "Split your data properly (remember that the British army wants to keep its time travel abilities in secret for a little longer). Split it such that you have 70% of the data in your training segment.\n",
    "Do you have missing values in your dataset? or any categorical values? deal with them with care.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116582, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precip</th>\n",
       "      <th>MorningTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNF</th>\n",
       "      <th>MiddayTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31401</td>\n",
       "      <td>1945-5-22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34104</td>\n",
       "      <td>1944-12-22</td>\n",
       "      <td>3.048</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13201</td>\n",
       "      <td>1944-7-17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32805</td>\n",
       "      <td>1944-8-18</td>\n",
       "      <td>0.254</td>\n",
       "      <td>27.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50401</td>\n",
       "      <td>1945-3-21</td>\n",
       "      <td>4.572</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STA        Date  Precip  MorningTemp  Snowfall  YR  MO  DA  PRCP  SNF  \\\n",
       "0  31401   1945-5-22   0.000    25.555556       0.0  45   5  22  0.00  0.0   \n",
       "1  34104  1944-12-22   3.048     3.888889       0.0  44  12  22  0.12  0.0   \n",
       "2  13201   1944-7-17   0.000    15.555556       0.0  44   7  17  0.00  0.0   \n",
       "3  32805   1944-8-18   0.254    27.777778       0.0  44   8  18  0.01  0.0   \n",
       "4  50401   1945-3-21   4.572    23.888889       0.0  45   3  21  0.18  0.0   \n",
       "\n",
       "   MiddayTemp  \n",
       "0   35.000000  \n",
       "1    7.777778  \n",
       "2   23.333333  \n",
       "3   36.111111  \n",
       "4   29.444444  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_royal = pd.read_csv(\"data/Royal_Dataset_of_Measurements.csv\")\n",
    "print(df_royal.shape)\n",
    "\n",
    "df_royal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>STATE/COUNTRY ID</th>\n",
       "      <th>ELEV</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33013</td>\n",
       "      <td>AL</td>\n",
       "      <td>611</td>\n",
       "      <td>36.383333</td>\n",
       "      <td>6.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33031</td>\n",
       "      <td>AL</td>\n",
       "      <td>88</td>\n",
       "      <td>35.616667</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33023</td>\n",
       "      <td>AL</td>\n",
       "      <td>23</td>\n",
       "      <td>36.716667</td>\n",
       "      <td>3.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33044</td>\n",
       "      <td>AL</td>\n",
       "      <td>754</td>\n",
       "      <td>36.116667</td>\n",
       "      <td>6.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12001</td>\n",
       "      <td>AL</td>\n",
       "      <td>443</td>\n",
       "      <td>27.683333</td>\n",
       "      <td>-8.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STA STATE/COUNTRY ID  ELEV  Longitude  Latitude\n",
       "0  33013               AL   611  36.383333  6.650000\n",
       "1  33031               AL    88  35.616667  0.583333\n",
       "2  33023               AL    23  36.716667  3.216667\n",
       "3  33044               AL   754  36.116667  6.416667\n",
       "4  12001               AL   443  27.683333 -8.083333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = pd.read_csv(\"data/data_weather_station_locations.csv\")\n",
    "print(df_weather.shape)\n",
    "\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116582, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Precip</th>\n",
       "      <th>MorningTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNF</th>\n",
       "      <th>MiddayTemp</th>\n",
       "      <th>STATE/COUNTRY ID</th>\n",
       "      <th>ELEV</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945-5-22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>DY</td>\n",
       "      <td>10</td>\n",
       "      <td>12.866667</td>\n",
       "      <td>44.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1944-12-22</td>\n",
       "      <td>3.048</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>IY</td>\n",
       "      <td>74</td>\n",
       "      <td>41.433333</td>\n",
       "      <td>15.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1944-7-17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>AZ</td>\n",
       "      <td>55</td>\n",
       "      <td>38.766667</td>\n",
       "      <td>-27.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944-8-18</td>\n",
       "      <td>0.254</td>\n",
       "      <td>27.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>IN</td>\n",
       "      <td>115</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>84.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1945-3-21</td>\n",
       "      <td>4.572</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>BZ</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.383333</td>\n",
       "      <td>-48.366667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Precip  MorningTemp  Snowfall  YR  MO  DA  PRCP  SNF  \\\n",
       "0   1945-5-22   0.000    25.555556       0.0  45   5  22  0.00  0.0   \n",
       "1  1944-12-22   3.048     3.888889       0.0  44  12  22  0.12  0.0   \n",
       "2   1944-7-17   0.000    15.555556       0.0  44   7  17  0.00  0.0   \n",
       "3   1944-8-18   0.254    27.777778       0.0  44   8  18  0.01  0.0   \n",
       "4   1945-3-21   4.572    23.888889       0.0  45   3  21  0.18  0.0   \n",
       "\n",
       "   MiddayTemp STATE/COUNTRY ID  ELEV  Longitude   Latitude  \n",
       "0   35.000000               DY    10  12.866667  44.866667  \n",
       "1    7.777778               IY    74  41.433333  15.616667  \n",
       "2   23.333333               AZ    55  38.766667 -27.033333  \n",
       "3   36.111111               IN   115  24.750000  84.966667  \n",
       "4   29.444444               BZ    13  -1.383333 -48.366667  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_royal.merge(df_weather, on='STA', how='left').drop('STA', axis=1)\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Date')\n",
    "\n",
    "df[\"STATE/COUNTRY ID\"] = df[\"STATE/COUNTRY ID\"].astype('category')\n",
    "df[\"STATE/COUNTRY ID\"] = df[\"STATE/COUNTRY ID\"].cat.codes\n",
    "\n",
    "X = df.drop(['MiddayTemp', 'Date'], axis=1).fillna(0)\n",
    "Y = df['MiddayTemp']\n",
    "\n",
    "X_train = X.iloc[:int(len(df)*0.7)]\n",
    "X_test = X.iloc[int(len(df)*0.7):]\n",
    "Y_train = Y.iloc[:int(len(df)*0.7)]\n",
    "Y_test = Y.iloc[int(len(df)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Precip</th>\n",
       "      <th>MorningTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNF</th>\n",
       "      <th>MiddayTemp</th>\n",
       "      <th>STATE/COUNTRY ID</th>\n",
       "      <th>ELEV</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111734</th>\n",
       "      <td>1940-1-1</td>\n",
       "      <td>2.286</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>-157.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>1940-1-1</td>\n",
       "      <td>7.620</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>-79.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19275</th>\n",
       "      <td>1940-1-1</td>\n",
       "      <td>0.254</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>26</td>\n",
       "      <td>271</td>\n",
       "      <td>21.483333</td>\n",
       "      <td>-158.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86227</th>\n",
       "      <td>1940-1-10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.111111</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>-157.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65314</th>\n",
       "      <td>1940-1-10</td>\n",
       "      <td>0.508</td>\n",
       "      <td>14.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>26</td>\n",
       "      <td>271</td>\n",
       "      <td>21.483333</td>\n",
       "      <td>-158.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Precip  MorningTemp  Snowfall  YR  MO  DA  PRCP  SNF  \\\n",
       "111734   1940-1-1   2.286    17.222222       0.0  40   1   1  0.09  0.0   \n",
       "10283    1940-1-1   7.620    22.222222       0.0  40   1   1  0.30  0.0   \n",
       "19275    1940-1-1   0.254    17.222222       0.0  40   1   1  0.01  0.0   \n",
       "86227   1940-1-10   0.000    16.666667       0.0  40   1  10  0.00  0.0   \n",
       "65314   1940-1-10   0.508    14.444444       0.0  40   1  10  0.02  0.0   \n",
       "\n",
       "        MiddayTemp  STATE/COUNTRY ID  ELEV  Longitude  Latitude  \n",
       "111734   26.666667                26     3  21.333333   -157.90  \n",
       "10283    28.333333                52     9   8.966667    -79.50  \n",
       "19275    23.333333                26   271  21.483333   -158.05  \n",
       "86227    26.111111                26     3  21.333333   -157.90  \n",
       "65314    23.333333                26   271  21.483333   -158.05  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Just for warmup: where are the forecasting stations? Show them all on a single map, using your favorite tools. There are rumors about this sophisticated tool called \"Google\" that can help you do it.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = df['Longitude']\n",
    "latitude = df['Latitude']\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(np.mean(longitude), np.mean(latitude), zoom=5)\n",
    "\n",
    "countr = 0\n",
    "for lon, lat in zip(longitude, latitude):\n",
    "    countr += 1\n",
    "    if countr == 10:\n",
    "        break\n",
    "    gmap.marker(lon, lat, color='cornflowerblue')\n",
    "\n",
    "gmap.draw('map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```I'm told that you need a definition for a loss function. well, I'm not such a technologist myself, but I can tell you that your loss should be linear in the absolute value of your error.\n",
    "A friend from the Royal Navy once told me, \"Aye stairt wi' a guid auld xgboost\". I trust this friend, and you should too. What results did you get?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 686325.900090494\n",
      "Test MSE 422847.2858020603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_GB = GradientBoostingRegressor()\n",
    "model_GB.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Train MSE\", mean_absolute_error(Y_train, model_GB.predict(X_train)))\n",
    "print(\"Test MSE\", mean_absolute_error(Y_test, model_GB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_GB = GradientBoostingRegressor(criterion='mae')\n",
    "\n",
    "max_depth = np.linspace(1, 20, 20, dtype=int)\n",
    "n_estimators = [10,40,80,120,180,200,250,300]\n",
    "learning_rate = np.logspace(-2, 0, 20)\n",
    "criterion = ['mae']\n",
    "min_samples_split = [5, 10, 15]\n",
    "min_samples_leaf = [1, 2, 4, 5]\n",
    "random_grid = {'learning_rate': learning_rate,\n",
    "               'n_estimators': n_estimators, \n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "\n",
    "random_model = RandomizedSearchCV(estimator=model_GB, param_distributions=random_grid,\n",
    "                                              n_iter=50, verbose=2, n_jobs=-1,\n",
    "                                              return_train_score=True, cv=3)\n",
    "random_model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Train MSE\", mean_absolute_error(Y_train, random_model.predict(X_train)))\n",
    "print(\"Test MSE\", mean_absolute_error(Y_test, random_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Heavens in the sky, that's not so good. This bloody scot, I never trusted him.\n",
    "Let's try a different approach. Another friend, from the Royal Airforce, told me, \"When you are preplexed and can't find your arms and legs, try training a neural net and look carefully at its loss\".\n",
    "I trust this friend very much. You should try what he suggested. Can you learn something to explains our poor results from earlier? Don't forget - neural networks work better when first normalizing your data.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81607,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,751\n",
      "Trainable params: 13,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Dropout, Softmax\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "model.add(Input((input_shape)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(15, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2721/2721 - 3s - loss: 122542.2969\n",
      "Epoch 2/10\n",
      "2721/2721 - 3s - loss: 122538.6328\n",
      "Epoch 3/10\n",
      "2721/2721 - 3s - loss: 122540.3281\n",
      "Epoch 4/10\n",
      "2721/2721 - 3s - loss: 122539.7734\n",
      "Epoch 5/10\n",
      "2721/2721 - 3s - loss: 122539.1953\n",
      "Epoch 6/10\n",
      "2721/2721 - 3s - loss: 122539.2266\n",
      "Epoch 7/10\n",
      "2721/2721 - 3s - loss: 122539.1875\n",
      "Epoch 8/10\n",
      "2721/2721 - 3s - loss: 122538.7969\n",
      "Epoch 9/10\n",
      "2721/2721 - 3s - loss: 122539.7109\n",
      "Epoch 10/10\n",
      "2721/2721 - 3s - loss: 122539.1953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d159916670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, Y_train, batch_size=30, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE 122539.96368545822\n",
      "Test MAE 2.010711598959717\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MAE\", mean_absolute_error(Y_train, model.predict(X_train_scaled)))\n",
    "print(\"Test MAE\", mean_absolute_error(Y_test, model.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```As I suspected.. The wanker Nazis must have poisoned our dataset! Intel tells me that they could insert one sample at most. Find it and delete it from our Royal Dataset.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "midday_temp = df['MiddayTemp'].values\n",
    "\n",
    "plt.hist(midday_temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 10000000000.0\n",
      "min 1.111111111\n",
      "mean 85804.32896063615\n",
      "median 29.44444444\n"
     ]
    }
   ],
   "source": [
    "print(\"max\", np.max(midday_temp))\n",
    "print(\"min\", np.min(midday_temp))\n",
    "print(\"mean\", np.mean(midday_temp))\n",
    "print(\"median\", np.median(midday_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.iloc[np.argmax(df['MiddayTemp'].values)].name)\n",
    "df = df.sort_values('Date')\n",
    "X = df.drop(['MiddayTemp', 'Date'], axis=1).fillna(0)\n",
    "Y = df['MiddayTemp']\n",
    "X_train = X.iloc[:int(len(df)*0.7)]\n",
    "X_test = X.iloc[int(len(df)*0.7):]\n",
    "Y_train = Y.iloc[:int(len(df)*0.7)]\n",
    "Y_test = Y.iloc[int(len(df)*0.7):]\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Blinding. Now train your xgboost and neural network again! What results can you get?\n",
    "Let me drop another tip for you: when you have an idea of the mean of the target you try to predict, you can initiate the last layer's bias to be this mean. It can make your network converge so much faster!```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 1.7964028722745808\n",
      "Test MSE 2.064153229731328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_GB = GradientBoostingRegressor()\n",
    "model_GB.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Train MSE\", mean_absolute_error(Y_train, model_GB.predict(X_train)))\n",
    "print(\"Test MSE\", mean_absolute_error(Y_test, model_GB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,751\n",
      "Trainable params: 13,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "2721/2721 - 2s - loss: 2.7590\n",
      "Epoch 2/10\n",
      "2721/2721 - 2s - loss: 1.7992\n",
      "Epoch 3/10\n",
      "2721/2721 - 2s - loss: 1.6201\n",
      "Epoch 4/10\n",
      "2721/2721 - 2s - loss: 1.5544\n",
      "Epoch 5/10\n",
      "2721/2721 - 2s - loss: 1.5133\n",
      "Epoch 6/10\n",
      "2721/2721 - 2s - loss: 1.4836\n",
      "Epoch 7/10\n",
      "2721/2721 - 2s - loss: 1.4628\n",
      "Epoch 8/10\n",
      "2721/2721 - 2s - loss: 1.4446\n",
      "Epoch 9/10\n",
      "2721/2721 - 3s - loss: 1.4285\n",
      "Epoch 10/10\n",
      "2721/2721 - 3s - loss: 1.4157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d14e5d0b50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "model.add(Input((input_shape)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(15, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='linear', weights = [np.zeros([15, 1]), np.mean(Y_train).reshape(1)]))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_scaled, Y_train, batch_size=30, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE 1.4114122637868352\n",
      "Test MAE 2.092658068355514\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MAE\", mean_absolute_error(Y_train, model.predict(X_train_scaled)))\n",
    "print(\"Test MAE\", mean_absolute_error(Y_test, model.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```I've got a new message from Bletchley. Apperantly, our troops are very sensitive to cold weather, but to warm weather? not so much. We should update our loss function accordingly. They gave me this formula, that I myself can't read, but you might:```\n",
    "\n",
    "$\\frac {\\sum_i {|Pred_i-True_i|}}{\\sum_i {Pred_i}}$\n",
    "\n",
    "```Does it do what we want it to do? Are there any visible problems with this loss? List here all the problems that come to your mind, regarding this loss. Assuming you have only one sample in your dataset, draw the loss as a function of your prediction. Also, evaluate your former models using this metric.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def new_loss(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_true-y_pred))/K.sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-ceded91aa711>:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  plt.plot(vec, np.abs(vec-true_val)/vec)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_val = 10\n",
    "vec = np.arange(-50,50,1)\n",
    "plt.plot(vec, np.abs(vec-true_val)/vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe main problem is that the limit is not the same from right and from left.\\nWhen we come from negative values, the limit is -inf, but when coming from positives vales, the limit is inf.\\n\\nSecondly, the function is no defined in 0, and not derivable. \\nFurthermore, the function is not convex. For gradient descent we need convex functions.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "the limit is not the same from right and from left.\n",
    "When we come from negative values, the limit is -inf, but when coming from positives vales, the limit is inf.\n",
    "\n",
    "Secondly, the function is no defined in 0, and not derivable. \n",
    "Furthermore, the function is not convex. For gradient descent we need convex functions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,751\n",
      "Trainable params: 13,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2721/2721 [==============================] - 3s 937us/step - loss: 0.1006\n",
      "Epoch 2/20\n",
      "2721/2721 [==============================] - 3s 942us/step - loss: 0.0669\n",
      "Epoch 3/20\n",
      "2721/2721 [==============================] - 2s 895us/step - loss: 0.0598\n",
      "Epoch 4/20\n",
      "2721/2721 [==============================] - 3s 991us/step - loss: 0.0568\n",
      "Epoch 5/20\n",
      "2721/2721 [==============================] - 3s 988us/step - loss: 0.0552\n",
      "Epoch 6/20\n",
      "2721/2721 [==============================] - 3s 971us/step - loss: 0.0539\n",
      "Epoch 7/20\n",
      "2721/2721 [==============================] - 3s 988us/step - loss: 0.0531\n",
      "Epoch 8/20\n",
      "2721/2721 [==============================] - 3s 1ms/step - loss: 0.0524\n",
      "Epoch 9/20\n",
      "2721/2721 [==============================] - 3s 1ms/step - loss: 0.0519\n",
      "Epoch 10/20\n",
      "2721/2721 [==============================] - 3s 1ms/step - loss: 0.0514\n",
      "Epoch 11/20\n",
      "2721/2721 [==============================] - 3s 985us/step - loss: 0.0509\n",
      "Epoch 12/20\n",
      "2721/2721 [==============================] - 3s 959us/step - loss: 0.0506\n",
      "Epoch 13/20\n",
      "2721/2721 [==============================] - 3s 967us/step - loss: 0.0502\n",
      "Epoch 14/20\n",
      "2721/2721 [==============================] - 3s 1ms/step - loss: 0.0500\n",
      "Epoch 15/20\n",
      "2721/2721 [==============================] - 3s 966us/step - loss: 0.0496\n",
      "Epoch 16/20\n",
      "2721/2721 [==============================] - 3s 1ms/step - loss: 0.0493\n",
      "Epoch 17/20\n",
      "2721/2721 [==============================] - 3s 943us/step - loss: 0.0491\n",
      "Epoch 18/20\n",
      "2721/2721 [==============================] - 3s 962us/step - loss: 0.0488\n",
      "Epoch 19/20\n",
      "2721/2721 [==============================] - 3s 979us/step - loss: 0.0485\n",
      "Epoch 20/20\n",
      "2721/2721 [==============================] - 3s 990us/step - loss: 0.0484\n",
      "Train MAE 1.3434432932110145\n",
      "Test MAE 2.1403933413920377\n"
     ]
    }
   ],
   "source": [
    "model_new_loss = Sequential()\n",
    "\n",
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "model_new_loss.add(Input((input_shape)))\n",
    "model_new_loss.add(Flatten())\n",
    "\n",
    "model_new_loss.add(Dense(100, activation='tanh'))\n",
    "model_new_loss.add(Dense(100, activation='tanh'))\n",
    "model_new_loss.add(Dense(20, activation='tanh'))\n",
    "model_new_loss.add(Dense(15, activation='tanh'))\n",
    "\n",
    "model_new_loss.add(Dense(1, activation='linear', weights = [np.zeros([15, 1]), np.mean(Y_train).reshape(1)]))\n",
    "model_new_loss.compile(loss='mae', optimizer='adam')\n",
    "model_new_loss.summary()\n",
    "\n",
    "model_new_loss.compile(loss=new_loss, optimizer='adam')\n",
    "\n",
    "model_new_loss.fit(X_train_scaled, Y_train, batch_size=30, epochs=20, verbose=1)\n",
    "\n",
    "print(\"Train MAE\", mean_absolute_error(Y_train, model_new_loss.predict(X_train_scaled)))\n",
    "print(\"Test MAE\", mean_absolute_error(Y_test, model_new_loss.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```That loss function seems a bit suspicious. Let's have a closer look. Implement it (for batches - why can't you properly train a sgd on this loss?), and see if the network exhibits reasonal behavior.\n",
    "The British people take pride for their meticulous examinations of networks. What happens if the network decides, for some reason, to predict negative values? Try train a network that initializes to predict negative values (maybe change the last bias again). Can you understand the behavior of the loss during training?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,751\n",
      "Trainable params: 13,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2721/2721 - 2s - loss: -1.1175e+00\n",
      "Epoch 2/20\n",
      "2721/2721 - 2s - loss: -1.1506e+00\n",
      "Epoch 3/20\n",
      "2721/2721 - 2s - loss: -1.2097e+00\n",
      "Epoch 4/20\n",
      "2721/2721 - 2s - loss: -1.3772e+00\n",
      "Epoch 5/20\n",
      "2721/2721 - 2s - loss: 15.5617\n",
      "Epoch 6/20\n",
      "2721/2721 - 2s - loss: 16.4910\n",
      "Epoch 7/20\n",
      "2721/2721 - 2s - loss: 9.5636\n",
      "Epoch 8/20\n",
      "2721/2721 - 2s - loss: 5.5067\n",
      "Epoch 9/20\n",
      "2721/2721 - 2s - loss: 3.0807\n",
      "Epoch 10/20\n",
      "2721/2721 - 2s - loss: 1.5768\n",
      "Epoch 11/20\n",
      "2721/2721 - 2s - loss: 0.6379\n",
      "Epoch 12/20\n",
      "2721/2721 - 2s - loss: 0.0681\n",
      "Epoch 13/20\n",
      "2721/2721 - 2s - loss: -1.8224e-01\n",
      "Epoch 14/20\n",
      "2721/2721 - 2s - loss: -2.0176e-01\n",
      "Epoch 15/20\n",
      "2721/2721 - 2s - loss: -2.0213e-01\n",
      "Epoch 16/20\n",
      "2721/2721 - 2s - loss: -2.0446e-01\n",
      "Epoch 17/20\n",
      "2721/2721 - 2s - loss: -1.9949e-01\n",
      "Epoch 18/20\n",
      "2721/2721 - 2s - loss: -1.9980e-01\n",
      "Epoch 19/20\n",
      "2721/2721 - 2s - loss: -2.0169e-01\n",
      "Epoch 20/20\n",
      "2721/2721 - 2s - loss: -1.9331e-01\n",
      "Train MAE 17.991564658720854\n",
      "Test MAE 14.906875832454906\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "model.add(Input((input_shape)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(15, activation='tanh'))\n",
    "\n",
    "model.add(Dense(1, activation='linear', weights = [np.ones([15, 1])*(-50), np.array([-1000]).reshape(1)]))\n",
    "model.compile(loss=new_loss, optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_scaled, Y_train, batch_size=30, epochs=20, verbose=2)\n",
    "\n",
    "print(\"Train MAE\", mean_absolute_error(Y_train, model.predict(X_train_scaled)))\n",
    "print(\"Test MAE\", mean_absolute_error(Y_test, model.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Compare neural networks trained with this special loss, with MSE and with MAE. Which one achieves the best MAE loss? which one achieves the best special loss?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Network trained with MAE loss: MAE = 2.09\n",
    "Network trained with new loss, initialized with positive values: MAE = 2.06\n",
    "Network trained with new loss, initialized with negative values: MAE = 14.91\n",
    "\n",
    "Best new loss was obtained by network trained on the new loss, initialized with negative values.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Iv'e just got an urgent message from the field marshal! He told me, \"Hoi, gent, my soldiers are cold! I have soldiers all around this damned globe, spread evenly, but you keep my boys worm only in a few damned countries!\". Do you think the field marchel is right? Why is that? Can you change the loss function to take this effect into account (bonus points if you can write it in LaTex)? Train a network using this loss.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_new_loss.predict(X_test).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34975,)\n",
      "(34975,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_predict.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "indices = np.where(np.abs(Y_test - y_predict) < 1)\n",
    "\n",
    "plt.hist(X_train['STATE/COUNTRY ID'].iloc[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.where(np.abs(Y_test - y_predict) >= 1)\n",
    "\n",
    "plt.hist(X_train['STATE/COUNTRY ID'].iloc[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "weights = 1/np.array(list(Counter(df['STATE/COUNTRY ID']).values()))\n",
    "weights = weights/np.sum(weights)\n",
    "weights_tensor = K.variable(weights.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss_weighted(y_true, y_pred_con):\n",
    "    return K.sum(weights_tensor * K.abs(y_true-y_pred))/K.sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,751\n",
      "Trainable params: 13,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2721/2721 - 2s - loss: -1.1173e+00\n",
      "Epoch 2/20\n",
      "2721/2721 - 2s - loss: -1.1509e+00\n",
      "Epoch 3/20\n",
      "2721/2721 - 2s - loss: -1.2101e+00\n",
      "Epoch 4/20\n",
      "2721/2721 - 2s - loss: -1.3793e+00\n",
      "Epoch 5/20\n",
      "2721/2721 - 2s - loss: 22.1421\n",
      "Epoch 6/20\n",
      "2721/2721 - 2s - loss: 40.6654\n",
      "Epoch 7/20\n",
      "2721/2721 - 2s - loss: 27.0186\n",
      "Epoch 8/20\n",
      "2721/2721 - 2s - loss: 18.2445\n",
      "Epoch 9/20\n",
      "2721/2721 - 2s - loss: 11.4770\n",
      "Epoch 10/20\n",
      "2721/2721 - 2s - loss: 6.9577\n",
      "Epoch 11/20\n",
      "2721/2721 - 2s - loss: 3.9461\n",
      "Epoch 12/20\n",
      "2721/2721 - 2s - loss: 2.1483\n",
      "Epoch 13/20\n",
      "2721/2721 - 2s - loss: 0.9956\n",
      "Epoch 14/20\n",
      "2721/2721 - 2s - loss: 0.2720\n",
      "Epoch 15/20\n",
      "2721/2721 - 2s - loss: -1.2102e-01\n",
      "Epoch 16/20\n",
      "2721/2721 - 2s - loss: -2.0244e-01\n",
      "Epoch 17/20\n",
      "2721/2721 - 3s - loss: -2.0822e-01\n",
      "Epoch 18/20\n",
      "2721/2721 - 2s - loss: -2.0332e-01\n",
      "Epoch 19/20\n",
      "2721/2721 - 2s - loss: -1.9654e-01\n",
      "Epoch 20/20\n",
      "2721/2721 - 2s - loss: -1.9725e-01\n",
      "Train MAE 17.87832286923655\n",
      "Test MAE 14.791266992156032\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 49.6 GiB for an array with shape (81606, 81606) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-bf577f753233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test MAE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_new_loss_weighted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New loss train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_new_loss_weighted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New loss test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_new_loss_weighted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-1c81b931fac6>\u001b[0m in \u001b[0;36mnew_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnew_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__sub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rsub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   4966\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4968\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4970\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;31m# error: \"None\" not callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 49.6 GiB for an array with shape (81606, 81606) and data type float64"
     ]
    }
   ],
   "source": [
    "model_new_loss_weighted = Sequential()\n",
    "\n",
    "input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "model_new_loss_weighted.add(Input((input_shape)))\n",
    "model_new_loss_weighted.add(Flatten())\n",
    "\n",
    "model_new_loss_weighted.add(Dense(100, activation='tanh'))\n",
    "model_new_loss_weighted.add(Dense(100, activation='tanh'))\n",
    "model_new_loss_weighted.add(Dense(20, activation='tanh'))\n",
    "model_new_loss_weighted.add(Dense(15, activation='tanh'))\n",
    "\n",
    "model_new_loss_weighted.add(Dense(1, activation='linear', weights = [np.ones([15, 1])*(-50), np.array([-1000]).reshape(1)]))\n",
    "model_new_loss_weighted.compile(loss=new_loss, optimizer='adam')\n",
    "model_new_loss_weighted.summary()\n",
    "\n",
    "model_new_loss_weighted.fit(X_train_scaled, Y_train, batch_size=30, epochs=20, verbose=2)\n",
    "\n",
    "print(\"Train MAE\", mean_absolute_error(Y_train, model_new_loss_weighted.predict(X_train_scaled)))\n",
    "print(\"Test MAE\", mean_absolute_error(Y_test, model_new_loss_weighted.predict(X_test_scaled)))\n",
    "\n",
    "print(\"New loss train\", new_loss(Y_train, model_new_loss_weighted.predict(X_train_scaled)))\n",
    "print(\"New loss test\", new_loss(Y_train, model_new_loss_weighted.predict(X_train_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_new_loss_weighted.predict(X_test).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.where(np.abs(Y_test - y_predict) < 1)\n",
    "\n",
    "plt.hist(X_train['STATE/COUNTRY ID'].iloc[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.where(np.abs(Y_test - y_predict) >= 1)\n",
    "\n",
    "plt.hist(X_train['STATE/COUNTRY ID'].iloc[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Something here smells fhisy as a drunk french on sunday morning. Try comparing the network you trained using the new loss with the other networks you trained so far, using all the metrics we used so far. What results did you get? Can you explain your results?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Higher MAE loss in this case, because of the weights.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
