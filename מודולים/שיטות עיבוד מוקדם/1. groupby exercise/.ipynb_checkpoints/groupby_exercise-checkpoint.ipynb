{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the exercise:\n",
    "\n",
    "## Author - Philip Tannor\n",
    "### This is not an exercise in which the whole problem should be solved. This is meant for the preprocessing stage, and is meant to help you learn to use pandas groupby in an efficient manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use these lines to read the data and get a basic feel for what they're like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2 alternative methods of reading the data\n",
    "# df = pd.read_csv(\"https://rodeo-tutorials.s3.amazonaws.com/data/credit-data-non-null.csv\")\n",
    "df = pd.read_csv('resources/credit-data-non-null.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print col\n",
    "    df[col].hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now create a new groupby object, using .groupby\n",
    "### start off by grouping by 'number_of_time30-59_days_past_due_not_worse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll try to use fuctions which operate on the different groups. Start off with the simple ones: .sum(), .mean(), .max(), .count(). Calculate each one of these in a different cell.\n",
    "### How are the records of the new DataFrame sorted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if you try to see the \"head\" of the groupby object? Why? Try using len() on the original object, and then on .head(1), .head(2), etc...\n",
    "### What if you try to use .iloc on it? or view the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try more complicated aggregations. For this, we use .agg(), and in the brackets put the functions we want to use as a list. Try this with np.mean and np.sum. Notice that this will create a index with multiple levels. Find a way to reset the index to be like a regular, useful, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now write 2 custom functions that calculate the 50th and 80th percentile of a pandas Series (using numpy). Add them to the list in the agg function. You should be calculating 4 features from each column in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You must have noticed, that not all the features calculated are useful. Now we will calculate only some of these features, for some of the columns. This we can do by placing a dictionary into the .agg function in this format: {'name_of_column1': [func1, func2, ...], 'name_of_column2': [func3, func4, ...]}.\n",
    "\n",
    "### Do this with the columns 'revolving_utilization_of_unsecured_lines' and 'age', and with 3 functions of your choice for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we'll try to complete tasks which involve storing all of the information of the group. Use a lambda function in the .agg() to save all of the ages in each group as a sorted list (each element should contribute one age). Use the python function sorted() in the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, generate a new DataFrame named 'random_ages' with 2 columns, and length 100. One is a random value of 'number_of_time30-59_days_past_due_not_worse' between 0 and 5, and the other in a random age between 20 and 50. Use np.random.randint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we'll try to convert the new DataFrame into \"age percentiles\", using the previous DataFrames of  lists. For this, use .apply() on the new DataFrame, and in the .apply() use a library called 'bisect'. This library will help you find the location of a new element in a sorted list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we tried sorting just one column as a list. Lets go back to the original groupby object, and think of a reason why we might want an internal sorting of the whole group. Try to get the value of the 'revolving_utilization_of_unsecured_lines' of the oldest person in each group (record with highest age).\n",
    "### This could be done in two different ways: using pandas Series sort_values within an apply function, or using the sort_values on the original DataFrame, before any groupby. Try both methods. Notice that in the second method, sort_values will have to sort by 2 columns (put their names in a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try applying groupby on the original DataFrame, inserting a list of more than one column (calculate someting with it). How is it sorted? When should this be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now parellelize any one of the calculations done, on the groupby object, in the previous cells. This may be accomplished with the map function on a pool from pathos.multiprocessing library (or similar). Notice this is easier on a linux machine (or via pycharm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
