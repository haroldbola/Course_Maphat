{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering\n",
    "In this exercise we will learn about the importance of feature engineering to improve our model's performance.\n",
    "We will be working on a kaggle dataset of kickstarter projects (if you don't know Kickstarter (shame on you!), your first assignment is to visit the <a href='https://www.kickstarter.com/'>Kickstarter</a> website and find a cool project).\n",
    "Each record represents one project and some basic information about it. \n",
    "\n",
    "The dataset can be found <a href='https://www.kaggle.com/kemical/kickstarter-projects#'> HERE </a>\n",
    "\n",
    "In this exercise we will try to predict whether a project will be a success or not (binary classification).\n",
    "\n",
    "Have fun :)\n",
    "\n",
    "``` ~Lior Hirsch ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```First, make sure all the following libraries are installed on you computer.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.635754Z",
     "start_time": "2020-10-21T08:17:24.659750Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "import itertools\n",
    "from currency_converter import CurrencyConverter\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.643755Z",
     "start_time": "2020-10-21T08:17:26.638754Z"
    }
   },
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning the data\n",
    "```The following code is a simple cleaning of the dataset. In the original dataset there are several states (which is the target column). Instead, we will use a new generated binary column based on the state column - output.```\n",
    "\n",
    "```Your first assignment is to create a train-test-split that will fit to our dataset.```\n",
    "\n",
    "#### Questions\n",
    "\n",
    "```How can you test whether the train-test-split is good?```\n",
    "\n",
    "```Explain your train-test-split proposal and why does it fit the dataset?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.678759Z",
     "start_time": "2020-10-21T08:17:26.645754Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(data):\n",
    "#     FILL HERE\n",
    "    return train_test_split(data.set_index(\"launched\").sort_index(), test_size = 0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.699751Z",
     "start_time": "2020-10-21T08:17:26.681751Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_clean_split_datasets():\n",
    "    ks = pd.read_csv('ks-projects-201801.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "    # Drop live projects\n",
    "    ks = ks[ks.state != 'live']\n",
    "\n",
    "    # Add outcome column, \"successful\" == 1, others are 0\n",
    "    ks['output'] = (ks['state'] == 'successful').astype(int)\n",
    "\n",
    "    # Drop pledged columns\n",
    "    ks = ks.drop(columns = ['pledged', 'backers', 'usd pledged', 'usd_pledged_real', 'usd_goal_real', 'state'])\n",
    "    \n",
    "    ks_train, ks_test = split(ks)\n",
    "    ks_train = ks_train.reset_index()\n",
    "    ks_test = ks_test.reset_index()\n",
    "    \n",
    "    return ks_train, ks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "```The following code builds a baseline model. Our data contains categorical columns. Therefore we need to encode them (Don't worry, we will learn about different encoders). For now we will use a basic encoding method called LabelEncoder. Read about this encoder. ```\n",
    "\n",
    "```Pay attention to the helper methods which will be used in this exercise.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.719756Z",
     "start_time": "2020-10-21T08:17:26.704752Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_xy_by_columns(df_train, df_test, columns):\n",
    "    x_train = ks_train[columns].copy()\n",
    "    y_train = ks_train['output'].copy()\n",
    "\n",
    "    x_test = ks_test[columns].copy()\n",
    "    y_test = ks_test['output'].copy()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.736752Z",
     "start_time": "2020-10-21T08:17:26.721751Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(x_train, x_val, y_train, y_val):\n",
    "    cls = xgb.XGBClassifier(n_jobs = -1, n_estimators=50, max_depth = 5, random_state=random_state)\n",
    "    cls.fit(x_train, y_train)\n",
    "    \n",
    "    preds = cls.predict_proba(x_train)\n",
    "    print(f\"AUC of ROC on train : {np.round(roc_auc_score(y_train, preds[:,1]), 4)}\")\n",
    "    \n",
    "    preds = cls.predict_proba(x_val)\n",
    "    print(f\"AUC of ROC on validation : {np.round(roc_auc_score(y_val, preds[:,1]), 4)}\")\n",
    "    \n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:28.616754Z",
     "start_time": "2020-10-21T08:17:26.739753Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country']\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Before fitting a model to our data, we need to encode the categorical data to a numeric/float types (Why?). LabelEncoder is a simple encoding method. Read about this encoder and use it.```\n",
    "\n",
    "```You might find categories in the test set which are not exist in the train set. Think how to fix this problem.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:31.863749Z",
     "start_time": "2020-10-21T08:17:28.618755Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "cat_features = ['category', 'main_category', 'currency', 'country']\n",
    "other_category = 'other'\n",
    "\n",
    "for curr_cat in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    x_train[curr_cat] = encoder.fit_transform(x_train[curr_cat])\n",
    "    \n",
    "    x_test[curr_cat] = x_test[curr_cat].map(lambda s: other_category if s not in encoder.classes_ else s)\n",
    "    encoder_classes = encoder.classes_.tolist()\n",
    "    encoder_classes.append(other_category)\n",
    "    encoder.classes_ = encoder_classes\n",
    "    x_test[curr_cat] = encoder.transform(x_test[curr_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:36.012705Z",
     "start_time": "2020-10-21T08:17:31.865753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.7282\n",
      "AUC of ROC on validation : 0.7199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date encoding\n",
    "```First, we'll start with a basic date encoding for the launch date and the deadline date. For each date, create three new columns - the hour, day and the month of the date. At the end of this encoding the data should contain six new columns - launched_hour, launched_day, launched_month, deadline_hour, deadline_day, deadline_month ```\n",
    "\n",
    "#### Questions\n",
    "```Why we won't create a column for the year?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:36.025724Z",
     "start_time": "2020-10-21T08:17:36.016706Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_launch_dt(df):\n",
    "    # FILL HERE\n",
    "    return df.assign(launched_hour=df.launched.dt.hour,\n",
    "                     launched_day=df.launched.dt.day,\n",
    "                     launched_month=df.launched.dt.month)\n",
    "\n",
    "def encode_deadline_dt(df):\n",
    "    # FILL HERE\n",
    "    return df.assign(deadline_hour=df.deadline.dt.hour,\n",
    "                     deadline_day=df.deadline.dt.day,\n",
    "                     deadline_month=df.deadline.dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:38.229754Z",
     "start_time": "2020-10-21T08:17:36.027713Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:38.367751Z",
     "start_time": "2020-10-21T08:17:38.231754Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Use the label encoder you used in the previous section to encode the categorical columns.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:41.656751Z",
     "start_time": "2020-10-21T08:17:38.369754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "cat_features = ['category', 'main_category', 'currency', 'country']\n",
    "other_category = 'other'\n",
    "\n",
    "for curr_cat in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    x_train[curr_cat] = encoder.fit_transform(x_train[curr_cat])\n",
    "    \n",
    "    x_test[curr_cat] = x_test[curr_cat].map(lambda s: other_category if s not in encoder.classes_ else s)\n",
    "    encoder_classes = encoder.classes_.tolist()\n",
    "    encoder_classes.append(other_category)\n",
    "    encoder.classes_ = encoder_classes\n",
    "    x_test[curr_cat] = encoder.transform(x_test[curr_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:45.921705Z",
     "start_time": "2020-10-21T08:17:41.658754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.7409\n",
      "AUC of ROC on validation : 0.7331\n"
     ]
    }
   ],
   "source": [
    "cls = fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding\n",
    "```Next, we will learn about different categorical encodings. Read how each encoding method works and try to understand when we should use each one of them. Be ready to discuss this with your tutor```\n",
    "\n",
    "```You can start by reading the following blog-posts:```\n",
    "\n",
    "https://wrosinski.github.io/fe_categorical_encoding/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:45.933706Z",
     "start_time": "2020-10-21T08:17:45.925705Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_encoding(x_train, x_val, col):\n",
    "    # FILL HERE\n",
    "    ce = (x_train.groupby(col)[col].agg(\"count\").rename(f'{col}_count')).reset_index()\n",
    "    x_train = x_train.merge(ce, on = col, how='left')\n",
    "    x_val = x_val.merge(ce, on = col, how='left')\n",
    "    \n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:48.186754Z",
     "start_time": "2020-10-21T08:17:45.935703Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:49.070756Z",
     "start_time": "2020-10-21T08:17:48.188753Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = ['category', 'main_category', 'currency', 'country']\n",
    "\n",
    "for curr_cat in cat_features:\n",
    "    x_train, x_test = count_encoding(x_train, x_test, curr_cat)\n",
    "    \n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "x_train = x_train.drop(columns=cat_features)\n",
    "x_test = x_test.drop(columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:53.243705Z",
     "start_time": "2020-10-21T08:17:49.072752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.742\n",
      "AUC of ROC on validation : 0.7331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoder\n",
    "```Target encoding can be used with/without smoothing. We will implement both types. We'll start without smoothing. Read about the difference between them.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:53.250703Z",
     "start_time": "2020-10-21T08:17:53.245703Z"
    }
   },
   "outputs": [],
   "source": [
    "# df - data, by - categorical column, on- target column, m - smoothing hyper-parameter - 0 will be without smoothing.\n",
    "def calc_smooth_mean(df, by, on, m = 0):\n",
    "    # FILL HERE\n",
    "    \n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:55.358757Z",
     "start_time": "2020-10-21T08:17:53.252703Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:56.373750Z",
     "start_time": "2020-10-21T08:17:55.360756Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "for curr_c in cat_features:\n",
    "    new_col_name = curr_c + \"_target\"\n",
    "    c_to_target = pd.DataFrame(calc_smooth_mean(ks_train, curr_c, 'output', m = 0), \n",
    "                               columns = [new_col_name])\n",
    "    ks_train = ks_train.join(c_to_target, on=curr_c)\n",
    "    ks_test = ks_test.join(c_to_target, on=curr_c)\n",
    "    relevant_columns.append(new_col_name)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "x_train = x_train.drop(columns=cat_features)\n",
    "x_test = x_test.drop(columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:00.355705Z",
     "start_time": "2020-10-21T08:17:56.379756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.7439\n",
      "AUC of ROC on validation : 0.7325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:02.458751Z",
     "start_time": "2020-10-21T08:18:00.358703Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:03.538755Z",
     "start_time": "2020-10-21T08:18:02.461754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "for curr_c in cat_features:\n",
    "    new_col_name = curr_c + \"_target\"\n",
    "    c_to_target = pd.DataFrame(calc_smooth_mean(ks_train, curr_c, 'output', m = 10), \n",
    "                               columns = [new_col_name])\n",
    "    ks_train = ks_train.join(c_to_target, on=curr_c)\n",
    "    ks_test = ks_test.join(c_to_target, on=curr_c)\n",
    "    relevant_columns.append(new_col_name)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "x_train = x_train.drop(columns=cat_features)\n",
    "x_test = x_test.drop(columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:07.841704Z",
     "start_time": "2020-10-21T08:18:03.540754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.7446\n",
      "AUC of ROC on validation : 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:10.140755Z",
     "start_time": "2020-10-21T08:18:07.844707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Catboost encoding\n",
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "\n",
    "cat_features = ['category', 'main_category', 'currency', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:11.549754Z",
     "start_time": "2020-10-21T08:18:10.142753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ex_fe\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "# FILL HERE\n",
    "target_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "target_enc.fit(x_train[cat_features], y_train)\n",
    "\n",
    "x_train = x_train.join(target_enc.transform(x_train[cat_features]).add_suffix('_cb'))\n",
    "x_test = x_test.join(target_enc.transform(x_test[cat_features]).add_suffix('_cb'))\n",
    "\n",
    "x_train.drop(columns=cat_features, inplace=True)\n",
    "x_test.drop(columns=cat_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:15.491706Z",
     "start_time": "2020-10-21T08:18:11.551753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.7441\n",
      "AUC of ROC on validation : 0.7376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "```Creating new features from the raw data is a powerful way to improve your model performance.```\n",
    "\n",
    "```In the following section we will generate the features and evaluate their impact in the end.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:17.712751Z",
     "start_time": "2020-10-21T08:18:15.493705Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country', 'launched', 'deadline',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "\n",
    "cat_features = ['category', 'main_category', 'currency', 'country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions\n",
    "```One of the easiest ways to create new features is by combining categorical variables. Create all the combinations of any two categoricals features. Don't forget to encode the new categorical features.```\n",
    "\n",
    "#### Questions\n",
    "```When is this not a good idea to and how it can be solved?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:18.673749Z",
     "start_time": "2020-10-21T08:18:17.714752Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE - create all the combinations\n",
    "for curr_pair in itertools.combinations(cat_features, 2):\n",
    "    combination_name = f'{curr_pair[0]}_{curr_pair[1]}'\n",
    "    interactions = x_train[curr_pair[0]] + \"_\" + x_train[curr_pair[1]]\n",
    "    x_train = x_train.assign(**{combination_name:interactions})\n",
    "    \n",
    "    interactions = x_test[curr_pair[0]] + \"_\" + x_test[curr_pair[1]]    \n",
    "    x_test = x_test.assign(**{combination_name:interactions})\n",
    "    cat_features.append(combination_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:23.405752Z",
     "start_time": "2020-10-21T08:18:18.675755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ex_fe\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "# FILL HERE - encode the categorical columns\n",
    "target_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "target_enc.fit(x_train[cat_features], y_train)\n",
    "\n",
    "x_train = x_train.join(target_enc.transform(x_train[cat_features]).add_suffix('_cb'))\n",
    "x_test = x_test.join(target_enc.transform(x_test[cat_features]).add_suffix('_cb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain knowledge \n",
    "```In this section we will create new features based on the original ones with a pinch of imagination and creativity. The domain knowledge features generation is one of the most successful ways to improve our model. ```\n",
    "\n",
    "```Don't forget to add the new features both to x_train, x_test```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Create a feature that contains the goal in USD currency```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.266751Z",
     "start_time": "2020-10-21T08:18:23.407754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "c = CurrencyConverter()\n",
    "train_goal_usd = x_train.apply(lambda x: c.convert(x.goal, x.currency, 'USD'), axis = 1)\n",
    "x_train['goal_usd'] = train_goal_usd\n",
    "\n",
    "test_goal_usd = x_test.apply(lambda x: c.convert(x.goal, x.currency, 'USD'), axis = 1)\n",
    "x_test['goal_usd'] = test_goal_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T10:31:07.636467Z",
     "start_time": "2020-10-13T10:31:07.631435Z"
    }
   },
   "source": [
    "```Count the number of projects launched in the preceeding week for each record.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.816753Z",
     "start_time": "2020-10-21T08:18:38.268754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "def add_7_days_counter(df):\n",
    "    launched = pd.Series(df.index, index=df.launched, name=\"count_7_days\").sort_index()\n",
    "    count_7_days = launched.rolling('7d').count() - 1\n",
    "    count_7_days.index = launched.values\n",
    "    count_7_days = count_7_days.reindex(df.index)\n",
    "    return df.join(count_7_days)\n",
    "\n",
    "x_train = add_7_days_counter(x_train).fillna(0)\n",
    "x_test = add_7_days_counter(x_test).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Count the days each project was online```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.847754Z",
     "start_time": "2020-10-21T08:18:38.818754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "online_days_train = (x_train.deadline - x_train.launched).dt.total_seconds() / (60 * 60* 24)\n",
    "online_days_test = (x_test.deadline - x_test.launched).dt.total_seconds() / (60 * 60* 24)\n",
    "\n",
    "x_train['online_days'] = online_days_train\n",
    "x_test['online_days'] = online_days_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Calculate the goal per day```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.861729Z",
     "start_time": "2020-10-21T08:18:38.849753Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "goal_per_day_train = (x_train.goal / online_days_train)\n",
    "goal_per_day_test = (x_test.goal / online_days_test)\n",
    "\n",
    "x_train['goal_per_day'] = goal_per_day_train\n",
    "x_test['goal_per_day'] = goal_per_day_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Calculate the goal per day in USD```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.879760Z",
     "start_time": "2020-10-21T08:18:38.863754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "goal_usd_per_day_train = x_train.goal_usd / online_days_train\n",
    "goal_usd_per_day_test = x_test.goal_usd / online_days_test\n",
    "\n",
    "x_train['goal_usd_per_day'] = goal_usd_per_day_train\n",
    "x_test['goal_usd_per_day'] = goal_usd_per_day_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Calculate the time since the last launch project in the same category```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:39.863755Z",
     "start_time": "2020-10-21T08:18:38.881755Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "def time_since_last_project(series):\n",
    "    # Return the time in hours\n",
    "    return series.diff().dt.days\n",
    "\n",
    "df = x_train[['category', 'launched']].sort_values('launched')\n",
    "timedeltas = df.groupby('category').transform(time_since_last_project)\n",
    "timedeltas = timedeltas.fillna(timedeltas.median()).reindex(x_train.index)\n",
    "x_train['timedeltas'] = timedeltas\n",
    "\n",
    "df = x_test[['category', 'launched']].sort_values('launched')\n",
    "timedeltas = df.groupby('category').transform(time_since_last_project)\n",
    "timedeltas = timedeltas.fillna(timedeltas.median()).reindex(x_test.index)\n",
    "x_test['timedeltas'] = timedeltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical features\n",
    "```Numerical features can be transformed with mathematical transformation like log, sqrt etc. Create another two features - log(goal_usd), sqrt(goal_usd)```\n",
    "\n",
    "#### Questions\n",
    "```Why are those transformation useful? ```\n",
    "\n",
    "```In which cases/ models we should use this transformation?```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:39.887750Z",
     "start_time": "2020-10-21T08:18:39.866726Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "sqrt_goal_usd = np.sqrt(x_train.goal_usd)\n",
    "log_goal_usd = np.log(x_train.goal_usd)\n",
    "x_train['sqrt_goal_usd'] = sqrt_goal_usd\n",
    "x_train['log_goal_usd'] = log_goal_usd\n",
    "\n",
    "sqrt_goal_usd = np.sqrt(x_test.goal_usd)\n",
    "log_goal_usd = np.log(x_test.goal_usd)\n",
    "x_test['sqrt_goal_usd'] = sqrt_goal_usd\n",
    "x_test['log_goal_usd'] = log_goal_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.637703Z",
     "start_time": "2020-10-21T08:18:39.889753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of ROC on train : 0.7676\n",
      "AUC of ROC on validation : 0.7433\n"
     ]
    }
   ],
   "source": [
    "features_to_remove = cat_features + ['deadline', 'launched']\n",
    "cls = fit_evaluate(x_train.drop(columns=features_to_remove), x_test.drop(columns=features_to_remove), y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Great! Now create another five unique and creative features that will make your tutor impressed and improve the model's validation AUC further. ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.642704Z",
     "start_time": "2020-10-21T08:18:49.639703Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.659704Z",
     "start_time": "2020-10-21T08:18:49.644703Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.674753Z",
     "start_time": "2020-10-21T08:18:49.661716Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.695759Z",
     "start_time": "2020-10-21T08:18:49.676726Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.716757Z",
     "start_time": "2020-10-21T08:18:49.697754Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex_fe",
   "language": "python",
   "name": "ex_fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
