{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering\n",
    "In this exercise we will learn about the importance of feature engineering to improve our model's performance.\n",
    "We will be working on a kaggle dataset of kickstarter projects (if you don't know Kickstarter (shame on you!), your first assignment is to visit the <a href='https://www.kickstarter.com/'>Kickstarter</a> website and find a cool project).\n",
    "Each record represents one project and some basic information about it. \n",
    "\n",
    "The dataset can be found <a href='https://www.kaggle.com/kemical/kickstarter-projects#'> HERE </a>\n",
    "\n",
    "In this exercise we will try to predict whether a project will be a success or not (binary classification).\n",
    "\n",
    "Have fun :)\n",
    "\n",
    "``` ~Lior Hirsch ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```First, make sure all the following libraries are installed on you computer.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.635754Z",
     "start_time": "2020-10-21T08:17:24.659750Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "import itertools\n",
    "from currency_converter import CurrencyConverter\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.643755Z",
     "start_time": "2020-10-21T08:17:26.638754Z"
    }
   },
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning the data\n",
    "```The following code is a simple cleaning of the dataset. In the original dataset there are several states (which is the target column). Instead, we will use a new generated binary column based on the state column - output.```\n",
    "\n",
    "```Your first assignment is to create a train-test-split that will fit to our dataset.```\n",
    "\n",
    "#### Questions\n",
    "\n",
    "```How can you test whether the train-test-split is good?```\n",
    "\n",
    "```Explain your train-test-split proposal and why does it fit the dataset?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.678759Z",
     "start_time": "2020-10-21T08:17:26.645754Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    return train_test_split(data.set_index(\"launched\").sort_index(), test_size = 0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.699751Z",
     "start_time": "2020-10-21T08:17:26.681751Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_clean_split_datasets():\n",
    "    ks = pd.read_csv('ks-projects-201801.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "    # Drop live projects\n",
    "    ks = ks[ks.state != 'live']\n",
    "\n",
    "    # Add outcome column, \"successful\" == 1, others are 0\n",
    "    ks['output'] = (ks['state'] == 'successful').astype(int)\n",
    "\n",
    "    # Drop pledged columns\n",
    "    ks = ks.drop(columns = ['pledged', 'backers', 'usd pledged', 'usd_pledged_real', 'usd_goal_real', 'state'])\n",
    "    \n",
    "    ks_train, ks_test = split(ks)\n",
    "    ks_train = ks_train.reset_index()\n",
    "    ks_test = ks_test.reset_index()\n",
    "    \n",
    "    return ks_train, ks_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "```The following code builds a baseline model. Our data contains categorical columns. Therefore we need to encode them (Don't worry, we will learn about different encoders). For now we will use a basic encoding method called LabelEncoder. Read about this encoder. ```\n",
    "\n",
    "```Pay attention to the helper methods which will be used in this exercise.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.719756Z",
     "start_time": "2020-10-21T08:17:26.704752Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_xy_by_columns(df_train, df_test, columns):\n",
    "    x_train = df_train[columns].copy()\n",
    "    y_train = df_train['output'].copy()\n",
    "\n",
    "    x_test = df_test[columns].copy()\n",
    "    y_test = df_test['output'].copy()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:26.736752Z",
     "start_time": "2020-10-21T08:17:26.721751Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(x_train, x_val, y_train, y_val):\n",
    "    cls = xgb.XGBClassifier(n_jobs = -1, n_estimators=50, max_depth = 5, random_state=random_state)\n",
    "    cls.fit(x_train, y_train)\n",
    "    \n",
    "    preds = cls.predict_proba(x_train)\n",
    "    print(f\"AUC of ROC on train : {np.round(roc_auc_score(y_train, preds[:,1]), 4)}\")\n",
    "    \n",
    "    preds = cls.predict_proba(x_val)\n",
    "    print(f\"AUC of ROC on validation : {np.round(roc_auc_score(y_val, preds[:,1]), 4)}\")\n",
    "    \n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:28.616754Z",
     "start_time": "2020-10-21T08:17:26.739753Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country']\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Before fitting a model to our data, we need to encode the categorical data to a numeric/float types (Why?). LabelEncoder is a simple encoding method. Read about this encoder and use it.```\n",
    "\n",
    "```You might find categories in the test set which are not exist in the train set. Think how to fix this problem.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:31.863749Z",
     "start_time": "2020-10-21T08:17:28.618755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "(300689,)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157]\n",
      "main_category\n",
      "(300689,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "currency\n",
      "(300689,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "goal\n",
      "country\n",
      "(300689,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n"
     ]
    }
   ],
   "source": [
    "for col in x_train.columns:\n",
    "    print(col)\n",
    "    if col == 'goal':\n",
    "        continue\n",
    "    encoder = LabelEncoder()\n",
    "    print(x_train[col].shape)\n",
    "    x_train[col] = encoder.fit_transform(x_train[col])\n",
    "    \n",
    "    print(encoder.classes_)\n",
    "    x_test[col] = x_test[col].map(lambda s: 'unknown' if s not in encoder.classes_ else s)\n",
    "    \n",
    "    encoder_classes = encoder.classes_.tolist()\n",
    "    encoder_classes.append('unknown')\n",
    "    encoder.classes_ = encoder_classes\n",
    "    \n",
    "    x_test[col] = encoder.transform(x_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       category  main_category  currency      goal  country\n",
      "0           109              2         4    4700.0        5\n",
      "1            89             10         9    2950.0       18\n",
      "2            12              9         9     500.0       18\n",
      "3            97              0         9    7000.0       18\n",
      "4            41              7         9   15000.0       18\n",
      "...         ...            ...       ...       ...      ...\n",
      "75168        68             10         0     500.0        1\n",
      "75169       150              9         9  100000.0       18\n",
      "75170       135              8         9    1000.0       18\n",
      "75171        25              1         5     100.0        9\n",
      "75172       135              8         1    5000.0        3\n",
      "\n",
      "[75173 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:36.012705Z",
     "start_time": "2020-10-21T08:17:31.865753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7301\n",
      "AUC of ROC on validation : 0.6763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date encoding\n",
    "```First, we'll start with a basic date encoding for the launch date and the deadline date. For each date, create three new columns - the hour, day and the month of the date. At the end of this encoding the data should contain six new columns - launched_hour, launched_day, launched_month, deadline_hour, deadline_day, deadline_month ```\n",
    "\n",
    "#### Questions\n",
    "```Why we won't create a column for the year?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:36.025724Z",
     "start_time": "2020-10-21T08:17:36.016706Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_launch_dt(df):\n",
    "    df['launched_hour'] = df.launched.dt.hour\n",
    "    df['launched_day'] = df.launched.dt.day\n",
    "    df['launched_month'] = df.launched.dt.month\n",
    "    return df\n",
    "\n",
    "def encode_deadline_dt(df):\n",
    "    df['deadline_hour'] = df.deadline.dt.hour\n",
    "    df['deadline_day'] = df.deadline.dt.day\n",
    "    df['deadline_month'] = df.deadline.dt.month\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:38.229754Z",
     "start_time": "2020-10-21T08:17:36.027713Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:38.367751Z",
     "start_time": "2020-10-21T08:17:38.231754Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Use the label encoder you used in the previous section to encode the categorical columns.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:41.656751Z",
     "start_time": "2020-10-21T08:17:38.369754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "main_category\n",
      "currency\n",
      "goal\n",
      "country\n",
      "launched_hour\n",
      "launched_day\n",
      "launched_month\n",
      "deadline_hour\n",
      "deadline_day\n",
      "deadline_month\n"
     ]
    }
   ],
   "source": [
    "for col in x_train.columns:\n",
    "    print(col)\n",
    "    if col == 'goal':\n",
    "        continue\n",
    "    encoder = LabelEncoder()\n",
    "    x_train[col] = encoder.fit_transform(x_train[curr_cat])\n",
    "    \n",
    "    x_test[col] = x_test[col].map(lambda s: 'unknown' if s not in encoder.classes_ else s)\n",
    "    \n",
    "    encoder_classes = encoder.classes_.tolist()\n",
    "    encoder_classes.append('unknown')\n",
    "    encoder.classes_ = encoder_classes\n",
    "    \n",
    "    x_test[col] = encoder.transform(x_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:45.921705Z",
     "start_time": "2020-10-21T08:17:41.658754Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.6607\n",
      "AUC of ROC on validation : 0.6388\n"
     ]
    }
   ],
   "source": [
    "cls = fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding\n",
    "```Next, we will learn about different categorical encodings. Read how each encoding method works and try to understand when we should use each one of them. Be ready to discuss this with your tutor```\n",
    "\n",
    "```You can start by reading the following blog-posts:```\n",
    "\n",
    "https://wrosinski.github.io/fe_categorical_encoding/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:45.933706Z",
     "start_time": "2020-10-21T08:17:45.925705Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_encoding(x_train, x_val, col):\n",
    "    ce = (x_train.groupby(col)[col].agg(\"count\").rename(f'{col}_count')).reset_index()\n",
    "    \n",
    "    x_train = x_train.merge(ce, on = col, how='left')\n",
    "    x_val = x_val.merge(ce, on = col, how='left')\n",
    "    \n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_encoding(x_train, x_val, col):\n",
    "    x_train[col] = x_train[col].astype('object').map(x_train[col].value_counts())\n",
    "    x_val[col] = x_val[col].astype('object').map(x_val[col].value_counts())\n",
    "        \n",
    "    x_train[col] = x_train[col].astype(np.float32)\n",
    "    x_val[col] = x_val[col].astype(np.float32)\n",
    "\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:48.186754Z",
     "start_time": "2020-10-21T08:17:45.935703Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['category', 'main_category', 'currency', 'country']\n",
    "\n",
    "for curr_cat in cat_features:\n",
    "    x_train, x_test = count_encoding(x_train, x_test, curr_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns\n",
    "\n",
    "x_train = x_train.drop(columns=cat_features)\n",
    "x_test = x_test.drop(columns=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:49.070756Z",
     "start_time": "2020-10-21T08:17:48.188753Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:53.243705Z",
     "start_time": "2020-10-21T08:17:49.072752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7435\n",
      "AUC of ROC on validation : 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoder\n",
    "```Target encoding can be used with/without smoothing. We will implement both types. We'll start without smoothing. Read about the difference between them.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:17:53.250703Z",
     "start_time": "2020-10-21T08:17:53.245703Z"
    }
   },
   "outputs": [],
   "source": [
    "# df - data, by - categorical column, on- target column, m - smoothing hyper-parameter - 0 will be without smoothing.\n",
    "def calc_smooth_mean(df, by, on, m = 0):\n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder(m_smoothing):\n",
    "    ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "    ks_train = encode_launch_dt(ks_train)\n",
    "    ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "    ks_test = encode_launch_dt(ks_test)\n",
    "    ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "    relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                         'launched_hour', 'launched_day', 'launched_month',\n",
    "                         'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "    \n",
    "    for curr_c in cat_features:\n",
    "        new_col_name = curr_c + \"_target\"\n",
    "        c_to_target = pd.DataFrame(calc_smooth_mean(ks_train, curr_c, 'output', m = m_smoothing), \n",
    "                                   columns = [new_col_name])\n",
    "        ks_train = ks_train.join(c_to_target, on=curr_c)\n",
    "        ks_test = ks_test.join(c_to_target, on=curr_c)\n",
    "        relevant_columns.append(new_col_name)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "    x_test = x_test.fillna(0)\n",
    "\n",
    "    x_train = x_train.drop(columns=cat_features)\n",
    "    x_test = x_test.drop(columns=cat_features)\n",
    "    \n",
    "    fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7463\n",
      "AUC of ROC on validation : 0.7308\n"
     ]
    }
   ],
   "source": [
    "target_encoder(m_smoothing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:03:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7456\n",
      "AUC of ROC on validation : 0.7302\n"
     ]
    }
   ],
   "source": [
    "target_encoder(m_smoothing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7452\n",
      "AUC of ROC on validation : 0.7294\n"
     ]
    }
   ],
   "source": [
    "target_encoder(m_smoothing=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:03:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7459\n",
      "AUC of ROC on validation : 0.7296\n"
     ]
    }
   ],
   "source": [
    "target_encoder(m_smoothing=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:10.140755Z",
     "start_time": "2020-10-21T08:18:07.844707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Catboost encoding\n",
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:11.549754Z",
     "start_time": "2020-10-21T08:18:10.142753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "cat_features = ['category', 'main_category', 'currency', 'country']\n",
    "\n",
    "target_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "target_enc.fit(x_train[cat_features], y_train)\n",
    "\n",
    "x_train = x_train.join(target_enc.transform(x_train[cat_features]).add_suffix('_cb'))\n",
    "x_test = x_test.join(target_enc.transform(x_test[cat_features]).add_suffix('_cb'))\n",
    "\n",
    "x_train.drop(columns=cat_features, inplace=True)\n",
    "x_test.drop(columns=cat_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:15.491706Z",
     "start_time": "2020-10-21T08:18:11.551753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.7456\n",
      "AUC of ROC on validation : 0.7351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "```Creating new features from the raw data is a powerful way to improve your model performance.```\n",
    "\n",
    "```In the following section we will generate the features and evaluate their impact in the end.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:17.712751Z",
     "start_time": "2020-10-21T08:18:15.493705Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "ks_train = encode_launch_dt(ks_train)\n",
    "ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "ks_test = encode_launch_dt(ks_test)\n",
    "ks_test = encode_deadline_dt(ks_test)\n",
    "\n",
    "relevant_columns = ['category', 'main_category', 'currency', 'goal', 'country', 'launched', 'deadline',\n",
    "                     'launched_hour', 'launched_day', 'launched_month',\n",
    "                     'deadline_hour', 'deadline_day', 'deadline_month']\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "\n",
    "cat_features = ['category', 'main_category', 'currency', 'country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions\n",
    "```One of the easiest ways to create new features is by combining categorical variables. Create all the combinations of any two categoricals features. Don't forget to encode the new categorical features.```\n",
    "\n",
    "#### Questions\n",
    "```When is this not a good idea to and how it can be solved?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['launched_hour', 'launched_day', 'launched_month', 'deadline_hour', 'deadline_day', 'deadline_month', 'category_main_category', 'category_currency', 'category_country', 'main_category_currency', 'main_category_country', 'currency_country']\n"
     ]
    }
   ],
   "source": [
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['launched', 'ID', 'name', 'category', 'main_category', 'currency',\n",
      "       'deadline', 'goal', 'country', 'output', 'category_main_category',\n",
      "       'category_currency', 'category_country', 'main_category_currency',\n",
      "       'main_category_country', 'currency_country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ks_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()\n",
    "\n",
    "cat_features = ['category', 'main_category', 'currency', 'country']\n",
    "\n",
    "# ks_train = encode_launch_dt(ks_train)\n",
    "# ks_train = encode_deadline_dt(ks_train)\n",
    "\n",
    "# ks_test = encode_launch_dt(ks_test)\n",
    "# ks_test = encode_deadline_dt(ks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:18.673749Z",
     "start_time": "2020-10-21T08:18:17.714752Z"
    }
   },
   "outputs": [],
   "source": [
    "comb_features = []\n",
    "\n",
    "for curr_pair in itertools.combinations(cat_features, 2):\n",
    "    combination_name = f'{curr_pair[0]}_{curr_pair[1]}'\n",
    "    interactions = ks_train[curr_pair[0]] + \"_\" + ks_train[curr_pair[1]]\n",
    "    ks_train = ks_train.assign(**{combination_name:interactions})\n",
    "    \n",
    "    interactions = ks_test[curr_pair[0]] + \"_\" + ks_test[curr_pair[1]]    \n",
    "    ks_test = ks_test.assign(**{combination_name:interactions})\n",
    "    \n",
    "    comb_features.append(combination_name)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, comb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:23.405752Z",
     "start_time": "2020-10-21T08:18:18.675755Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:31:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.6916\n",
      "AUC of ROC on validation : 0.6709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_columns = []\n",
    "cat_features = ['category', 'main_category', 'currency', 'country', 'category_main_category', \n",
    "                'category_currency', 'category_country', 'main_category_currency', \n",
    "                'main_category_country', 'currency_country']\n",
    "\n",
    "for curr_c in cat_features:\n",
    "    new_col_name = curr_c + \"_target\"\n",
    "    c_to_target = pd.DataFrame(calc_smooth_mean(ks_train, curr_c, 'output', m = 0), \n",
    "                               columns = [new_col_name])\n",
    "    ks_train = ks_train.join(c_to_target, on=curr_c)\n",
    "    ks_test = ks_test.join(c_to_target, on=curr_c)\n",
    "    relevant_columns.append(new_col_name)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, relevant_columns)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'main_category', 'currency', 'country', 'category_cb',\n",
       "       'main_category_cb', 'currency_cb', 'country_cb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "target_enc = ce.CatBoostEncoder(cols=comb_features)\n",
    "target_enc.fit(x_train[comb_features], y_train)\n",
    "\n",
    "x_train = target_enc.transform(x_train[comb_features]).add_suffix('_cb')\n",
    "x_test = target_enc.transform(x_test[comb_features]).add_suffix('_cb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category_main_category_cb', 'category_currency_cb',\n",
       "       'category_country_cb', 'main_category_currency_cb',\n",
       "       'main_category_country_cb', 'currency_country_cb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300689, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.691\n",
      "AUC of ROC on validation : 0.6768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain knowledge \n",
    "```In this section we will create new features based on the original ones with a pinch of imagination and creativity. The domain knowledge features generation is one of the most successful ways to improve our model. ```\n",
    "\n",
    "```Don't forget to add the new features both to x_train, x_test```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Create a feature that contains the goal in USD currency```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_train, ks_test = load_clean_split_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.266751Z",
     "start_time": "2020-10-21T08:18:23.407754Z"
    }
   },
   "outputs": [],
   "source": [
    "c = CurrencyConverter()\n",
    "\n",
    "train_goal_usd = ks_train.apply(lambda x: c.convert(x.goal, x.currency, 'USD'), axis = 1)\n",
    "ks_train['goal_usd'] = train_goal_usd\n",
    "\n",
    "test_goal_usd = ks_test.apply(lambda x: c.convert(x.goal, x.currency, 'USD'), axis = 1)\n",
    "ks_test['goal_usd'] = test_goal_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T10:31:07.636467Z",
     "start_time": "2020-10-13T10:31:07.631435Z"
    }
   },
   "source": [
    "```Count the number of projects launched in the preceeding week for each record.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.816753Z",
     "start_time": "2020-10-21T08:18:38.268754Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_7_days_counter(df):\n",
    "    launched = pd.Series(df.index, index=df.launched, name=\"count_7_days\").sort_index()\n",
    "    count_7_days = launched.rolling('7d').count() - 1\n",
    "    count_7_days.index = launched.values\n",
    "    count_7_days = count_7_days.reindex(df.index)\n",
    "    return df.join(count_7_days)\n",
    "\n",
    "ks_train = add_7_days_counter(ks_train).fillna(0)\n",
    "ks_test = add_7_days_counter(ks_test).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Count the days each project was online```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.847754Z",
     "start_time": "2020-10-21T08:18:38.818754Z"
    }
   },
   "outputs": [],
   "source": [
    "online_days_train = (ks_train.deadline - ks_train.launched).dt.total_seconds() / (60 * 60* 24)\n",
    "online_days_test = (ks_test.deadline - ks_test.launched).dt.total_seconds() / (60 * 60* 24)\n",
    "\n",
    "ks_train['online_days'] = online_days_train\n",
    "ks_test['online_days'] = online_days_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Calculate the goal per day```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.861729Z",
     "start_time": "2020-10-21T08:18:38.849753Z"
    }
   },
   "outputs": [],
   "source": [
    "goal_per_day_train = (ks_train.goal / online_days_train)\n",
    "goal_per_day_test = (ks_test.goal / online_days_test)\n",
    "\n",
    "ks_train['goal_per_day'] = goal_per_day_train\n",
    "ks_test['goal_per_day'] = goal_per_day_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Calculate the goal per day in USD```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:38.879760Z",
     "start_time": "2020-10-21T08:18:38.863754Z"
    }
   },
   "outputs": [],
   "source": [
    "goal_usd_per_day_train = ks_train.goal_usd / online_days_train\n",
    "goal_usd_per_day_test = ks_test.goal_usd / online_days_test\n",
    "\n",
    "ks_train['goal_usd_per_day'] = goal_usd_per_day_train\n",
    "ks_test['goal_usd_per_day'] = goal_usd_per_day_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Calculate the time since the last launch project in the same category```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:39.863755Z",
     "start_time": "2020-10-21T08:18:38.881755Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_since_last_project(series):\n",
    "    # Return the time in hours\n",
    "    return series.diff().dt.days\n",
    "\n",
    "df = ks_train[['category', 'launched']].sort_values('launched')\n",
    "timedeltas = df.groupby('category').transform(time_since_last_project)\n",
    "timedeltas = timedeltas.fillna(timedeltas.median()).reindex(ks_train.index)\n",
    "ks_train['timedeltas'] = timedeltas\n",
    "\n",
    "df = ks_test[['category', 'launched']].sort_values('launched')\n",
    "timedeltas = df.groupby('category').transform(time_since_last_project)\n",
    "timedeltas = timedeltas.fillna(timedeltas.median()).reindex(ks_test.index)\n",
    "ks_test['timedeltas'] = timedeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['launched', 'ID', 'name', 'category', 'main_category', 'currency',\n",
      "       'deadline', 'goal', 'country', 'output', 'goal_usd', 'count_7_days',\n",
      "       'online_days', 'goal_per_day', 'goal_usd_per_day', 'timedeltas'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ks_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.763\n",
      "AUC of ROC on validation : 0.7405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_features = ['launched', 'name', 'category', 'main_category', 'currency',\n",
    "       'deadline', 'goal', 'country', 'output', 'goal_usd', 'count_7_days',\n",
    "       'online_days', 'goal_per_day', 'goal_usd_per_day', 'timedeltas']\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_xy_by_columns(ks_train, ks_test, created_features)\n",
    "\n",
    "for col in x_train.columns:\n",
    "    if x_train[col].dtype == 'object':\n",
    "        new_col_name = col + \"_target\"\n",
    "        c_to_target = pd.DataFrame(calc_smooth_mean(x_train, col, 'output', m = 0), columns = [new_col_name])\n",
    "        \n",
    "        x_train = x_train.join(c_to_target, on=col)\n",
    "        x_test = x_test.join(c_to_target, on=col)\n",
    "\n",
    "        x_train = x_train.drop(columns=[col])\n",
    "        x_test = x_test.drop(columns=[col])\n",
    "\n",
    "x_train = x_train.drop(columns=['launched', 'deadline', 'output', 'name_target'])\n",
    "x_test = x_test.drop(columns=['launched', 'deadline', 'output', 'name_target'])\n",
    "\n",
    "fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal                    float64\n",
      "goal_usd                float64\n",
      "count_7_days            float64\n",
      "online_days             float64\n",
      "goal_per_day            float64\n",
      "goal_usd_per_day        float64\n",
      "timedeltas              float64\n",
      "category_target         float64\n",
      "main_category_target    float64\n",
      "currency_target         float64\n",
      "country_target          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical features\n",
    "```Numerical features can be transformed with mathematical transformation like log, sqrt etc. Create another two features - log(goal_usd), sqrt(goal_usd)```\n",
    "\n",
    "#### Questions\n",
    "```Why are those transformation useful? ```\n",
    "\n",
    "```In which cases/ models we should use this transformation?```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:39.887750Z",
     "start_time": "2020-10-21T08:18:39.866726Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train['sqrt_goal_usd'] = np.sqrt(x_train.goal_usd)\n",
    "x_train['log_goal_usd'] = np.log(x_train.goal_usd)\n",
    "x_train = x_train.drop(columns=['goal_usd'])\n",
    "\n",
    "x_test['sqrt_goal_usd'] = np.sqrt(x_test.goal_usd)\n",
    "x_test['log_goal_usd'] = np.log(x_test.goal_usd)\n",
    "x_test = x_test.drop(columns=['goal_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.637703Z",
     "start_time": "2020-10-21T08:18:39.889753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:33:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.763\n",
      "AUC of ROC on validation : 0.7405\n"
     ]
    }
   ],
   "source": [
    "cls = fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Great! Now create another five unique and creative features that will make your tutor impressed and improve the model's validation AUC further. ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.642704Z",
     "start_time": "2020-10-21T08:18:49.639703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal                    float64\n",
      "count_7_days            float64\n",
      "online_days             float64\n",
      "goal_per_day            float64\n",
      "goal_usd_per_day        float64\n",
      "timedeltas              float64\n",
      "category_target         float64\n",
      "main_category_target    float64\n",
      "currency_target         float64\n",
      "country_target          float64\n",
      "sqrt_goal_usd           float64\n",
      "log_goal_usd            float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>count_7_days</th>\n",
       "      <th>online_days</th>\n",
       "      <th>goal_per_day</th>\n",
       "      <th>goal_usd_per_day</th>\n",
       "      <th>timedeltas</th>\n",
       "      <th>category_target</th>\n",
       "      <th>main_category_target</th>\n",
       "      <th>currency_target</th>\n",
       "      <th>country_target</th>\n",
       "      <th>sqrt_goal_usd</th>\n",
       "      <th>log_goal_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.006890e+05</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>3.006890e+05</td>\n",
       "      <td>3.006890e+05</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "      <td>300689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.636754e+04</td>\n",
       "      <td>1148.418765</td>\n",
       "      <td>34.336245</td>\n",
       "      <td>2.359769e+03</td>\n",
       "      <td>2.328624e+03</td>\n",
       "      <td>1.036895</td>\n",
       "      <td>0.354855</td>\n",
       "      <td>0.354855</td>\n",
       "      <td>0.354855</td>\n",
       "      <td>0.354855</td>\n",
       "      <td>108.563596</td>\n",
       "      <td>8.618998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.137464e+06</td>\n",
       "      <td>529.899760</td>\n",
       "      <td>73.724752</td>\n",
       "      <td>5.315815e+05</td>\n",
       "      <td>5.317754e+05</td>\n",
       "      <td>64.988081</td>\n",
       "      <td>0.140423</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>0.044398</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>181.880981</td>\n",
       "      <td>1.689463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>2.832798e-04</td>\n",
       "      <td>2.832798e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>0.197720</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-4.605170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>29.100972</td>\n",
       "      <td>6.683388e+01</td>\n",
       "      <td>6.687477e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263831</td>\n",
       "      <td>0.299421</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.376282</td>\n",
       "      <td>44.721360</td>\n",
       "      <td>7.600902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>29.732558</td>\n",
       "      <td>1.710775e+02</td>\n",
       "      <td>1.713067e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341752</td>\n",
       "      <td>0.336858</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.376282</td>\n",
       "      <td>70.710678</td>\n",
       "      <td>8.517193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.500000e+04</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>38.014028</td>\n",
       "      <td>5.013495e+02</td>\n",
       "      <td>4.995274e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436132</td>\n",
       "      <td>0.408456</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.376282</td>\n",
       "      <td>122.474487</td>\n",
       "      <td>9.615805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>4012.000000</td>\n",
       "      <td>16738.958333</td>\n",
       "      <td>2.903031e+08</td>\n",
       "      <td>2.903031e+08</td>\n",
       "      <td>14498.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.629836</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.376282</td>\n",
       "      <td>11746.411741</td>\n",
       "      <td>18.742606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               goal   count_7_days    online_days  goal_per_day  \\\n",
       "count  3.006890e+05  300689.000000  300689.000000  3.006890e+05   \n",
       "mean   4.636754e+04    1148.418765      34.336245  2.359769e+03   \n",
       "std    1.137464e+06     529.899760      73.724752  5.315815e+05   \n",
       "min    1.000000e-02       0.000000       0.035498  2.832798e-04   \n",
       "25%    2.000000e+03     820.000000      29.100972  6.683388e+01   \n",
       "50%    5.000000e+03    1073.000000      29.732558  1.710775e+02   \n",
       "75%    1.500000e+04    1478.000000      38.014028  5.013495e+02   \n",
       "max    1.000000e+08    4012.000000   16738.958333  2.903031e+08   \n",
       "\n",
       "       goal_usd_per_day     timedeltas  category_target  main_category_target  \\\n",
       "count      3.006890e+05  300689.000000    300689.000000         300689.000000   \n",
       "mean       2.328624e+03       1.036895         0.354855              0.354855   \n",
       "std        5.317754e+05      64.988081         0.140423              0.100830   \n",
       "min        2.832798e-04       0.000000         0.060156              0.197720   \n",
       "25%        6.687477e+01       0.000000         0.263831              0.299421   \n",
       "50%        1.713067e+02       0.000000         0.341752              0.336858   \n",
       "75%        4.995274e+02       0.000000         0.436132              0.408456   \n",
       "max        2.903031e+08   14498.000000         0.750000              0.629836   \n",
       "\n",
       "       currency_target  country_target  sqrt_goal_usd   log_goal_usd  \n",
       "count    300689.000000   300689.000000  300689.000000  300689.000000  \n",
       "mean          0.354855        0.354855     108.563596       8.618998  \n",
       "std           0.044398        0.057900     181.880981       1.689463  \n",
       "min           0.188437        0.027661       0.100000      -4.605170  \n",
       "25%           0.372411        0.376282      44.721360       7.600902  \n",
       "50%           0.372411        0.376282      70.710678       8.517193  \n",
       "75%           0.372411        0.376282     122.474487       9.615805  \n",
       "max           0.372411        0.376282   11746.411741      18.742606  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL HERE\n",
    "print(x_train.dtypes)\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.659704Z",
     "start_time": "2020-10-21T08:18:49.644703Z"
    }
   },
   "outputs": [],
   "source": [
    "# FILL HERE\n",
    "x_train['sqrt_country_target'] = np.sqrt(x_train.country_target)\n",
    "x_train['log_country_target'] = np.log(x_train.country_target)\n",
    "x_train = x_train.drop(columns=['country_target'])\n",
    "\n",
    "x_test['sqrt_country_target'] = np.sqrt(x_test.country_target)\n",
    "x_test['log_country_target'] = np.log(x_test.country_target)\n",
    "x_test = x_test.drop(columns=['country_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:33:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.763\n",
      "AUC of ROC on validation : 0.7405\n"
     ]
    }
   ],
   "source": [
    "cls = fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.674753Z",
     "start_time": "2020-10-21T08:18:49.661716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RONENAH\\Anaconda3\\envs\\formation_env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:36:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC of ROC on train : 0.763\n",
      "AUC of ROC on validation : 0.7405\n"
     ]
    }
   ],
   "source": [
    "# FILL HERE\n",
    "x_train['sqrt_goal'] = np.sqrt(x_train.goal)\n",
    "x_train['log_goal'] = np.log(x_train.goal)\n",
    "x_train = x_train.drop(columns=['goal'])\n",
    "\n",
    "x_test['sqrt_goal'] = np.sqrt(x_test.goal)\n",
    "x_test['log_goal'] = np.log(x_test.goal)\n",
    "x_test = x_test.drop(columns=['goal'])\n",
    "\n",
    "cls = fit_evaluate(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T08:18:49.695759Z",
     "start_time": "2020-10-21T08:18:49.676726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count_7_days', 'online_days', 'goal_per_day', 'goal_usd_per_day',\n",
       "       'timedeltas', 'category_target', 'main_category_target',\n",
       "       'currency_target', 'sqrt_goal_usd', 'log_goal_usd',\n",
       "       'sqrt_country_target', 'log_country_target', 'sqrt_goal', 'log_goal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL HERE\n",
    "x_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
