{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Work and The Transferability Principle\n",
    "```In this exercise you will experience with real experimental work and will meet a very interesting issue - adversarial AI and the transferability principle. You will define experiments and measures for success, and will execute those experiments. It is of great importance that you will discuss this exercise with your tutor, even during the work on the exercise.```\n",
    "\n",
    "```~Ohad Amosi & Ittai Haran```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Read the paper \"Adversarial Examples Are Not Bugs, They Are Features\", which you can find in this exercise directory. Read it thoroughly. Make sure you understand how the datasets of experiments #1 and #2 were generated. As you might tell, the paper reports very interesting results.```\n",
    "\n",
    "```If you are not familiar with the concept of model distillation, read about it. There arise the question, how can we be sure that the \"non-robust\" features described in the paper are real? Could it be that the effect the paper measures is a model distillation? Think about it: In both the experiments the authors used a trained robust network to label images, on which another network was trained normally. Could it be that the robust network was somehow \"leaked\"? Think about this possibility, and how it could have happen in experiment #1 and experiment #2.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "In distillation training, one model is trained to predict the output probabilities of another model that was trained on an earlier, baseline standard to emphasize accuracy.\n",
    "\n",
    "In the case of the first experiment, robust model is used to create a robust dataset.\n",
    "We want to replace each sample x in the original dataset by a sample x_r. x and x_r must be very close in the latent space of a robust model.\n",
    "We use only the representation layer of the robust model, not the output probabilities and then it is not a distillation training. Furthermore, the new sample x_r does not lie in the latent sapce, but in the input space\n",
    "\n",
    "Experiment #2 does not use a robust model, but creates advresarial example to show that good classification can be achieved only based on non-robust features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```All in all, we will examine two conjectures:```\n",
    "1. ```The paper is great, non-robust features are the real thing and different networks use the same features.```\n",
    "2. ```The paper is wrong, it's only a fancy way of network distilling.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Let's first explore the concept of distilling networks. Can we do it in any case? Can you distill a network using only, for example, white noise? Can you do it using only the predictions? Or do you maybe need to use the logits of the network? Answer this question. MNIST might help you with that.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivideLayer(Layer):\n",
    "    def __init__(self, temperature=1, **kwargs):\n",
    "        self.temperature = temperature\n",
    "        super(DivideLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return  inputs / self.temperature\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, input_shape, num_classes, temperature=1):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            DivideLayer(temperature),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=3)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "#     model.summary()\n",
    "    model.fit(x_train, y_train, batch_size=256, epochs=15, validation_split=0.1, callbacks=[es])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distillation(temperature=1, use_proba=True):\n",
    "    num_classes = 10\n",
    "    input_shape = (28, 28, 1)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    teacher = train_model(x_train, y_train, input_shape, num_classes, temperature=temperature)\n",
    "    \n",
    "    if use_proba is True:\n",
    "        train_probas = teacher.predict(x_train)\n",
    "    \n",
    "    student = train_model(x_train, train_probas, input_shape, num_classes, temperature=temperature)\n",
    "    \n",
    "    return teacher, student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.3593 - accuracy: 0.8892 - val_loss: 0.0810 - val_accuracy: 0.9793\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 23s 56ms/step - loss: 0.1151 - accuracy: 0.9649 - val_loss: 0.0587 - val_accuracy: 0.9832\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0851 - accuracy: 0.9736 - val_loss: 0.0474 - val_accuracy: 0.9870\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0726 - accuracy: 0.9769 - val_loss: 0.0465 - val_accuracy: 0.9875\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0644 - accuracy: 0.9798 - val_loss: 0.0398 - val_accuracy: 0.9890\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 23s 54ms/step - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.0375 - val_accuracy: 0.9895\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0339 - val_accuracy: 0.9910\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0508 - accuracy: 0.9839 - val_loss: 0.0348 - val_accuracy: 0.9895\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 23s 54ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.0320 - val_accuracy: 0.9905\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.0304 - val_accuracy: 0.9912\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 23s 55ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 23s 56ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0269 - val_accuracy: 0.9932\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 24s 56ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0283 - val_accuracy: 0.9918\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 24s 56ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0272 - val_accuracy: 0.9915\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 24s 56ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.0275 - val_accuracy: 0.9922\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8ff25f7b5b91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mteacher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_distillation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-7aa5275693ee>\u001b[0m in \u001b[0;36mtrain_distillation\u001b[1;34m(temperature, use_proba)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_proba\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtrain_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mstudent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_probas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "teacher, student = train_distillation(use_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Distilling using only white noise is a though question. Why is it? Think about the concepts of distribution and out-of-distribution in when answering this.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "```Assuming conjecture #2 and regarding experiment #1, the distillation isn't happening on white noise, but not on real images either. Think of an experiment that will help you decide if the phenomenon the authors encountered is indeed just network distillation. Think how to measure your success. Open the hint only if you can't think of a way do to it.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "```You can, for example, take a dataset such as CIFAR10, train a network on 5 classes and try to distill it using the other 5 classes. That way you are using real images, but from different distributions.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Let's focus now on conjecture #1. Conduct an experiment that will demonstrate that two different networks indeed use the same features. Do it gradually: Start with two copies of the same architecture and on the same data, and move to different architectures and different subsets of the data (but from the same distribution). Think how to measure your success.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
