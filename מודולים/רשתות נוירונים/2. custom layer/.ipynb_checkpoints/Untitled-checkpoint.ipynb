{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "three-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "national-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subsequence(sequence, subsequence):\n",
    "    idx = 0\n",
    "    for char in sequence:\n",
    "        if char == subsequence[idx]:\n",
    "            idx += 1\n",
    "        if idx == len(subsequence):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "unable-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = [0, 1, 2, 3, 4, 5, 6]\n",
    "padding_length = 25\n",
    "n_sequences = 100000\n",
    "\n",
    "def create_seq(baseline_in, padding_length, p=0.5, padding_symbol=8):\n",
    "    baseline_length_in = len(baseline_in)\n",
    "    baseline_places = []\n",
    "    seq = []\n",
    "    count = 0\n",
    "    while count<baseline_length_in:\n",
    "        if np.random.random()<p:\n",
    "            digit_copy = digits.copy()\n",
    "            digit_copy.remove(baseline_in[count])\n",
    "            seq.append(np.random.choice(digit_copy, 1)[0])\n",
    "        else:\n",
    "            baseline_places.append(len(seq))\n",
    "            seq.append(baseline_in[count])\n",
    "            count += 1\n",
    "\n",
    "    if len(seq) < padding_length:\n",
    "        seq += [padding_symbol] * (padding_length-len(seq))\n",
    "        \n",
    "    return seq, baseline_places\n",
    "\n",
    "def create_wrong_seq(padding_length, baseline_in, padding_symbol=8):\n",
    "    do_again=True\n",
    "    while do_again is True:\n",
    "        len_seq = np.random.randint(1, 10)\n",
    "\n",
    "        seq = np.random.choice(digits, len_seq).tolist()\n",
    "        seq += [padding_symbol] * (padding_length-len(seq))\n",
    "        \n",
    "        do_again = find_subsequence(seq, baseline_in)\n",
    "    return seq, []\n",
    "    \n",
    "def create_sequences(count, baseline_in):\n",
    "    return map(lambda x: create_seq(baseline_in, padding_length=padding_length), range(count))\n",
    "\n",
    "\n",
    "def create_wrong_sequences(count, baseline_in):\n",
    "    return map(lambda x: create_wrong_seq(padding_length=padding_length, \n",
    "                                          baseline_in=baseline_in), range(count))\n",
    "\n",
    "baseline_length = 3\n",
    "right_baseline = [1,3,2]\n",
    "\n",
    "good_list = list(create_sequences(n_sequences, right_baseline))\n",
    "wrong_list = list(create_wrong_sequences(n_sequences, right_baseline))\n",
    "\n",
    "data = good_list + wrong_list\n",
    "data, places = list(map(lambda x: x[0], data)), list(map(lambda x: x[1], data))\n",
    "target = [True]*n_sequences+[False]*n_sequences\n",
    "\n",
    "good_data = good_list\n",
    "good_data, places = list(map(lambda x: x[0], good_data)), list(map(lambda x: x[1], good_data))\n",
    "        \n",
    "data = np.array(data)\n",
    "good_data = np.array(good_data)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "favorite-greeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6 0 4 6 0 3 1 6 4 3 2 8 8 8 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "print(good_data[1946])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "elegant-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 2 4 2 2 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "print(data[17541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "expressed-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (20000, 25, 1)\n",
      "good_data (10000, 25, 1)\n",
      "target (20000,)\n"
     ]
    }
   ],
   "source": [
    "data = data.reshape(data.shape[0], data.shape[1], 1)\n",
    "print('data', data.shape)\n",
    "\n",
    "good_data = good_data.reshape(good_data.shape[0], good_data.shape[1], 1)\n",
    "print('good_data', good_data.shape)\n",
    "\n",
    "print('target', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "earned-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "data_train, data_val, target_train, target_val = train_test_split(data, target,\n",
    "                                                                  test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "continuing-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(data_train)\n",
    "BATCH_SIZE = 200\n",
    "steps_per_epoch = len(data_train)//BATCH_SIZE\n",
    "units = 64\n",
    "\n",
    "data_train = tf.convert_to_tensor(data_train, dtype=tf.dtypes.float32)\n",
    "good_data = tf.convert_to_tensor(good_data, dtype=tf.dtypes.float32)\n",
    "data = tf.convert_to_tensor(data, dtype=tf.dtypes.float32)\n",
    "target_train = tf.convert_to_tensor(target_train, dtype=tf.dtypes.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_train, target_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "strong-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units), dtype=tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "incoming-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([200, 25, 1]), TensorShape([200]))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "turkish-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (200, 25, 64)\n",
      "Encoder Hidden state shape: (batch size, units) (200, 64)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "perceived-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, sequence_length, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, sequence_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "outstanding-pickup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (200, 64)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (200, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "underlying-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        #     self.fc = tf.keras.layers.Dense(1)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([context_vector, x], axis=-1)\n",
    "        x = tf.expand_dims(x, 1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        x = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "equipped-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(tf.keras.Model):\n",
    "    def __init__(self, batch_sz):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.fc1 = tf.keras.layers.Dense(32, activation='tanh')\n",
    "        self.fc4 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "bibliographic-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (200, 64)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "mediterranean-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "vocal-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False, label_smoothing=0, reduction=\"auto\", name=\"binary_crossentropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "tough-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        all_out_dec = []\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(0, inp.shape[1]):\n",
    "            dec_input = inp[:, t, :]\n",
    "            out_dec, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            all_out_dec.append(out_dec)\n",
    "            \n",
    "        all_out_dec = tf.concat(all_out_dec, axis=-1)\n",
    "        prediction = classifier(all_out_dec)\n",
    "\n",
    "        loss = loss_fn(prediction, targ)\n",
    "        batch_loss = (loss / int(inp.shape[1]))\n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables + classifier.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "popular-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.04371343553066254 Acc 0.9396596550941467\n",
      "Time taken for 1 epoch 46.92895007133484 sec\n",
      "\n",
      "Epoch 2 Loss 0.019535483792424202 Acc 0.9396541118621826\n",
      "Time taken for 1 epoch 54.2650363445282 sec\n",
      "\n",
      "Epoch 3 Loss 0.01553440187126398 Acc 0.9538410902023315\n",
      "Time taken for 1 epoch 60.58668780326843 sec\n",
      "\n",
      "Epoch 4 Loss 0.015768110752105713 Acc 0.9601109623908997\n",
      "Time taken for 1 epoch 58.76879143714905 sec\n",
      "\n",
      "Epoch 5 Loss 0.012362102046608925 Acc 0.9636350274085999\n",
      "Time taken for 1 epoch 46.2893443107605 sec\n",
      "\n",
      "Epoch 6 Loss 0.013626608066260815 Acc 0.9667780995368958\n",
      "Time taken for 1 epoch 45.638553619384766 sec\n",
      "\n",
      "Epoch 7 Loss 0.014852236025035381 Acc 0.9681528806686401\n",
      "Time taken for 1 epoch 45.63822674751282 sec\n",
      "\n",
      "Epoch 8 Loss 0.05081391707062721 Acc 0.9670646786689758\n",
      "Time taken for 1 epoch 47.37821435928345 sec\n",
      "\n",
      "Epoch 9 Loss 0.03583740070462227 Acc 0.9604979157447815\n",
      "Time taken for 1 epoch 51.84011173248291 sec\n",
      "\n",
      "Epoch 10 Loss 0.016284482553601265 Acc 0.9607878923416138\n",
      "Time taken for 1 epoch 46.30239725112915 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "Acc_class = tf.keras.metrics.Accuracy(name=\"accuracy\", dtype=None)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    all_acc = []\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss, prediction = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        acc_batch = Acc_class(np.round(prediction), targ)\n",
    "        all_acc.append(acc_batch)\n",
    "\n",
    "    print('Epoch {} Loss {} Acc {}'.format(epoch + 1, total_loss / steps_per_epoch, \n",
    "                                           np.mean(all_acc)))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "august-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sequence):\n",
    "    attention_plot = np.zeros((padding_length, padding_length))\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(sequence, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    all_out_dec = []\n",
    "\n",
    "    for t in range(0, padding_length):\n",
    "        dec_input = sequence[:, t, :]\n",
    "        out_dec, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        all_out_dec.append(out_dec)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    all_out_dec = tf.concat(all_out_dec, axis=-1)\n",
    "    result = classifier(all_out_dec)\n",
    "\n",
    "    return result, sequence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "composed-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels(np.roll(sentence, 1), fontdict=fontdict)\n",
    "    ax.set_yticklabels(np.roll(sentence, 1), fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "later-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 25, 1)\n",
      "(10000, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(good_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "racial-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention(idx):\n",
    "    sequence = tf.expand_dims(good_data[idx], 0)\n",
    "\n",
    "    result, sentence, attention_plot = evaluate(sequence)\n",
    "    seq_numpy = sequence.numpy()\n",
    "    seq_numpy = seq_numpy.reshape(-1)\n",
    "    \n",
    "    plot_attention(attention_plot, seq_numpy, seq_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "identified-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-392-02e7a5da5daf>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(np.roll(sentence, 1), fontdict=fontdict)\n",
      "<ipython-input-392-02e7a5da5daf>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(np.roll(sentence, 1), fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_attention(idx=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-consumer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
