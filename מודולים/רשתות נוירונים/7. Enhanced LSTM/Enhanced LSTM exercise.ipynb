{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced LSTM exercise\n",
    "```In this exercise you will implement the article \"Enhanced LSTM for Natural Language Inference\" with the objective to achieve the performances of the article's experiments. The main goals of this exercise:```\n",
    "1. ```Experiment with low-level programming of DNN, specifically RNN and LSTM architectures.```\n",
    "2. ```To get familiar with the \"Attention mechanism\" in nueral networks```\n",
    "3. ```Learn some good practice about the use of neural networks in the NLP domain.```\n",
    "\n",
    "\n",
    "```The purpose of this exercise is to acquire skills of independent work, and implementation of articles by your own.\n",
    "You need to implement everything by yourself, and this notebook is only an abstract, non-mandatory guide for your work.\n",
    "Please keep in mind that you are required to implement the preprocessing of the data, the models, and all the pipeline by yourself. Therefore, it is a great opportunity to practice \"non-notebook\" programming, and ordered and efficient code design.```\n",
    "\n",
    "```Note: No kaggle cheats! this means no computing features by mixing the train and the test. Think creatively how to handle train-test differences (very relevant to NLP and Embedding layers)\n",
    "This is a research process. You are going to come along with unknown topics, theoretical gaps, and implementation challenges.\n",
    "Please document all the above challenges in the format: what is the challenge? how you are going to solve it? conclusions from the solving process. You will discuss all the above with your tutor. (The documentation will be yours to keep and use for help in the future)```\n",
    "\n",
    "```~Gilad Royz & Gal Eyal```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Just read the article, and try to understand it completely.\n",
    "While reading, Discuss with your tutor about questions that comes up.```\n",
    "\n",
    "```Tip: try to explain the article to someone not familiar with it. It will help you realize how well you understood it.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```You can find some information about the dataset and the task in the README.txt file (found in the data folder: \"snli_1.0\")\n",
    "Here is code that reads the data:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('snli_1.0/snli_1.0_train.txt', sep='\\t')\n",
    "dev = pd.read_csv('snli_1.0/snli_1.0_dev.txt', sep='\\t')\n",
    "test = pd.read_csv('snli_1.0/snli_1.0_test.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['gold_label'] != '-']\n",
    "dev = dev[dev['gold_label'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['gold_label'].map({'entailment' : 0, 'neutral' : 1, 'contradiction' : 2})\n",
    "y_dev = dev['gold_label'].map({'entailment' : 0, 'neutral' : 1, 'contradiction' : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```In the article, they used word embeddings of \"GloVe\". You are very encouraged to read about it.\n",
    "Question: How is it different from word2vec? (answer here)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Here is a code that load the embedding```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "embeddings = []\n",
    "with open('glove.840B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        parsed_line = line.replace('\\n', '').split(' ', 1)\n",
    "        word = parsed_line[0]\n",
    "        vector = np.fromstring(parsed_line[1], sep=' ')\n",
    "        \n",
    "        words.append(word)\n",
    "        embeddings.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```You are going to implement the models using the platform of \"dynet\".\n",
    "It has properties that might help implementing the models from the article.\n",
    "The biggest advantage is it's ability to dynamically change the network computation graph in runtime, what makes it possible to build a different graph of the network for every new sentence. (cool ahh?)```\n",
    "\n",
    "```If you want to work with other platform like pytorch, tensorflow, or even keras (if you feel lucky, punk), get your tutor approval and suggestions.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1> Important NOTE: please write the <b>final</b> implementation in .py file and not in notebooks. This is not negotiable! </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynet\n",
    "### documentation in: https://dynet.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```After you read the article and you know what is the ESIM model, you are going to implement it.\n",
    "You are expected to implement it from zero. (with dynet its not the end of the world)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree ESIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```If you like adventures, you can implement the Tree-lstm yourself, but there is a git that contain a good structure that can be useful for the implementation here (you will need to change and adjust it! no free meals)```\n",
    "\n",
    "```the git address:``` ```https://github.com/clab/dynet/tree/master/examples/treelstm```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```You are also given a parser for the sentences tree expression in the dataset (it is an adjusted version of the \"tree.py\" in the git). You are very welcome to use it (will save you some time).```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Here is a demonstration:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "santance = train['sentence1_binary_parse'][0]\n",
    "santance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_example = Tree.from_sexpr(santance, '<NODE>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tree_example.leaves():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tree_example.nonterms():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```The format is: [root [left] [right]], and for father of sole leaf: [root leaf]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Inference Model (HIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Explained perfectly in the article```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some questions to think about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```1. How to treat words that are not part of training data in test time ?```\n",
    "\n",
    "```2. How to deal with rare words?```\n",
    "\n",
    "```3. What are the input state and input of the inner nodes in the lstm-tree?```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good luck!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
