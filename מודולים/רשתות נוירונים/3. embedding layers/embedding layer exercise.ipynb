{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember to save this as a new notebook before you begin solving!! \n",
    "# Also remember to open the notebook through a virtual env that works well with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This exercise is meant to teach you how to use embedding layers, and how to create a recommendation system. The data we'll use is the data from the Netflix Prize. This exercise should come after you have some experience with NN (not necessarily extensive experience)\n",
    "\n",
    "### Author: Philip Tannor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description: The first line of each 'batch of movies' contains the movie_id followed by a colon. Each subsequent line in the file corresponds to a rating from a customer and its date in the following format:\n",
    "CustomerID,Rating,Date\n",
    "MovieIDs range from 1 to 17770 sequentially. \n",
    "CustomerIDs range from 1 to 2649429, with gaps. \n",
    "There are 480189 users. \n",
    "Ratings are on a five star (integral) scale from 1 to 5. \n",
    "Dates have the format YYYY-MM-DD.\n",
    "\n",
    "#### Note that originally the data was stored with one movie per file. This is a new, easier, format created by a kaggler (DLao @ Hong Kong) with a later touch of Ittai Haran.\n",
    "Since I don't think that arranging the data teaches very much, I left the basic lines of preprocessing that I did. Feel free to delete it and start over - just make sure to split the data on your own to train and test (randomly). \n",
    "If you're more hard-working than I am - used the dates in the original data to split in a more realistic manner (regarding time). Notice there is an apparent leakage - since we create the dictionaries base on all of the data. This is intentional, and also realistic (we can't use these ML techniques for new users or movies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'grade', 'date', 'num'], dtype='object')\n",
      "(100000, 4)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 100480507\n",
    "s = 100000\n",
    "skip = sorted(random.sample(range(1,n+1),n-s))\n",
    "\n",
    "df = pd.read_csv(\"resources/combined_data.csv\", skiprows=skip)\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'grade', 'date', 'num'], dtype='object')\n",
      "(500000, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"resources/combined_data.csv\", nrows=500000)\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>178520</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>1257939</td>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>1700782</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>380354</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>753663</td>\n",
       "      <td>148</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating\n",
       "499995   178520       148       3\n",
       "499996  1257939       148       5\n",
       "499997  1700782       148       2\n",
       "499998   380354       148       1\n",
       "499999   753663       148       4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we drop the date since this isn't used for the embedding model\n",
    "df = df.rename(columns = {'num': 'movie_id', 'grade': 'rating'}).drop('date', axis = 1)[['user_id', 'movie_id', 'rating']]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (500000, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Dataset shape: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('rating', axis = 1), df.rating, test_size = 0.3, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell creates dictionaries which help with changing the unique ID's into series of int's. \n",
    "#This is neccessary for embedding layers in keras (so use the transformed columns later on), \n",
    "#especially if you only use part of the data.\n",
    "\n",
    "list_unique = list(set(df.user_id))\n",
    "transforming_user = {v:k for k,v in zip(range(len(list_unique)), list_unique)}\n",
    "list_unique = list(set(df.movie_id))\n",
    "transforming_movie = {v:k for k,v in zip(range(len(list_unique)), list_unique)}\n",
    "\n",
    "X_train['user_id_transformed'] = X_train['user_id'].apply(lambda x: transforming_user[x])\n",
    "X_train['movie_id_transformed'] = X_train['movie_id'].apply(lambda x: transforming_movie[x])\n",
    "\n",
    "X_test['user_id_transformed'] = X_test['user_id'].apply(lambda x: transforming_user[x])\n",
    "X_test['movie_id_transformed'] = X_test['movie_id'].apply(lambda x: transforming_movie[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, now go through the instructions - and then you'll be on your own for a while. \n",
    "\n",
    "1. Read about embedding layers here: https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12. The explanation isn't detailed enough, but you should try to think of the layer as a change of representation - from a very sparse one-hot vector (which is equivalent), to a dense vector of much lower dimension. In the new representation, each element really means something - and sometimes these elements may be translated into a scale which correlated with some intuitive feature (age, connection holocaust content, spendable income, etc.). \n",
    "2. Pay attention that this function which creates the change of representation (the embedding layer) is learned as the network trains. This means that at the beginning - the elements in the new representation won't mean much, but as the learning progresses the representation will be more and more meaningful.\n",
    "3. Create a neural network in Keras (use functional API - *NOT SEQUENTIAL*. This will become important later on). The NN should have 2 different embedding layers - one which get the user_id as inputs, and one that gets the movie_id as input. I won't tell you the dimension of the 2 new representations - play around with these 2 numbers. Intuitively - try to think how many number you would need to describe a user (same thing for a movie). Notice that 'input_dim' is the size of the vocabulary (and not '1').\n",
    "4. These embedding layers should be merged, and then flattened. After this, add a few dense layers. If you get the hang of the training and don't want to wait too long, or if you want to compare to my model, read the model in the hidden answers folder using keras.model.load_model. TL;DR - the saved model reaches an MSE of a bit less than 0.72.\n",
    "5. The output should be a single number - this can be treated as a regression problem, or as an ordinal classification problem. Originally, it was treated as a regression problem by Netflix, so your output should be a floating number between 1 and 5 and you should minimize the MSE.\n",
    "6. Bonus: treat this as an ordinal classification problem, and use the loss from this paper (squared EMD): https://arxiv.org/abs/1611.05916. This bonus shouldn't be attempted if this is the first time you've dealt with custom losses or ordinal classification. Also, notice there is more work to be done later on in the notebook (which isn't \"a bonus\")!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215008\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "list_unique_user_id = list(set(df.user_id))\n",
    "print(len(list_unique_user_id))\n",
    "\n",
    "list_unique_movie_id = list(set(df.movie_id))\n",
    "print(len(list_unique_movie_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, concatenate, Flatten\n",
    "\n",
    "user_dim = 15\n",
    "movie_dim = 8\n",
    "\n",
    "x_user = Input(shape = (1,))\n",
    "embedding_user = Embedding(input_dim = len(list_unique_user_id), output_dim = user_dim, dtype='float32', input_length=1)(x_user)\n",
    "\n",
    "x_movie = Input(shape = (1,))\n",
    "embedding_movie = Embedding(input_dim = len(list_unique_movie_id), output_dim = movie_dim, dtype='float32', input_length=1)(x_movie)\n",
    "\n",
    "concat = concatenate([embedding_user, embedding_movie], axis = -1)\n",
    "\n",
    "flatten = Flatten()(concat)\n",
    "dense1 = Dense(units = (user_dim + movie_dim), activation = 'tanh')(flatten)\n",
    "dense2 = Dense(units = int((user_dim + movie_dim)), activation = 'tanh')(dense1)\n",
    "dense3 = Dense(units = int((user_dim + movie_dim)), activation = 'tanh')(dense2)\n",
    "# dense4 = Dense(units = int((user_dim + movie_dim)), activation = 'tanh')(dense3)\n",
    "output_layer = Dense(units = 1, activation = 'linear')(dense3)\n",
    "\n",
    "model = Model(inputs = [x_user, x_movie], outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 15)        3225120     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 8)         1184        input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1, 23)        0           embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 23)           0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 23)           552         flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 23)           552         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 23)           552         dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1)            24          dense_42[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,227,984\n",
      "Trainable params: 3,227,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "350/350 [==============================] - 19s 54ms/step - loss: 8.9703 - val_loss: 2.4293\n",
      "Epoch 2/100\n",
      "350/350 [==============================] - 19s 53ms/step - loss: 1.2649 - val_loss: 1.0557\n",
      "Epoch 3/100\n",
      "350/350 [==============================] - 17s 49ms/step - loss: 1.0024 - val_loss: 1.0197\n",
      "Epoch 4/100\n",
      "350/350 [==============================] - 18s 50ms/step - loss: 0.9347 - val_loss: 1.0131\n",
      "Epoch 5/100\n",
      "350/350 [==============================] - 18s 51ms/step - loss: 0.8422 - val_loss: 1.0302\n",
      "Epoch 6/100\n",
      "350/350 [==============================] - 18s 52ms/step - loss: 0.7390 - val_loss: 1.0729\n",
      "Epoch 7/100\n",
      "350/350 [==============================] - 19s 55ms/step - loss: 0.6506 - val_loss: 1.1223\n",
      "Epoch 8/100\n",
      "350/350 [==============================] - 18s 52ms/step - loss: 0.5854 - val_loss: 1.1617\n",
      "Epoch 9/100\n",
      "350/350 [==============================] - 18s 51ms/step - loss: 0.5395 - val_loss: 1.1916\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21a24af0220>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "callbacks_list = [es]\n",
    "\n",
    "model.fit(x=[X_train['user_id_transformed'], X_train['movie_id_transformed']], y=y_train, \n",
    "         validation_data=([X_test['user_id_transformed'], X_test['movie_id_transformed']], y_test),\n",
    "         epochs=100, verbose=1, batch_size = 1000, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.323474e+06</td>\n",
       "      <td>9070.212670</td>\n",
       "      <td>3.606480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.647833e+05</td>\n",
       "      <td>5151.669201</td>\n",
       "      <td>1.084709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.900000e+01</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.636540e+05</td>\n",
       "      <td>4661.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.321212e+06</td>\n",
       "      <td>9049.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.983551e+06</td>\n",
       "      <td>13651.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.649426e+06</td>\n",
       "      <td>17770.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id       movie_id         rating\n",
       "count  1.000000e+05  100000.000000  100000.000000\n",
       "mean   1.323474e+06    9070.212670       3.606480\n",
       "std    7.647833e+05    5151.669201       1.084709\n",
       "min    7.900000e+01       3.000000       1.000000\n",
       "25%    6.636540e+05    4661.000000       3.000000\n",
       "50%    1.321212e+06    9049.000000       4.000000\n",
       "75%    1.983551e+06   13651.000000       4.000000\n",
       "max    2.649426e+06   17770.000000       5.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! If you've reached here, you manged to create a neural network which uses embeddings and can predict movie rankings using only very basic information (unique ID's). \n",
    "Now we want to turn this into a recommendation system. Write a function which gets one specific user_id as an input, and outputs 10 names of movies with the highest expected ratings. Read the file named movie_titles.csv to connect between the movie id's and the names of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('resources/movie_titles.csv', header = None)#, names = ['movie_id', 'year', 'name'])\n",
    "\n",
    "movies_dict = {v: k for v, k in zip(movies_df[0], movies_df[2])}\n",
    "untransforming_movie = {v: k for k, v in transforming_movie.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_10(user):\n",
    "    recommend_df = pd.DataFrame(list(set(X_test.movie_id_transformed)), \n",
    "                                columns = ['movie_id_transformed'])\n",
    "    recommend_df['user_id_transformed'] = [transforming_user[user]] * len(recommend_df)\n",
    "    recommend_df['predictions'] = model.predict([recommend_df['user_id_transformed'], \n",
    "                                                 recommend_df['movie_id_transformed']])\n",
    "    \n",
    "    top_10 = recommend_df.sort_values('predictions', ascending = False).head(10)\n",
    "    top_10['movie_id'] = top_10.movie_id_transformed.apply(lambda x: untransforming_movie[x])\n",
    "    \n",
    "    return top_10.movie_id.apply(lambda x: movies_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    Lord of the Rings: The Return of the King: Ext...\n",
       "17                                     Immortal Beloved\n",
       "27                                      Lilo and Stitch\n",
       "24        Inspector Morse 31: Death Is Now My Neighbour\n",
       "29                               Something's Gotta Give\n",
       "2                                             Character\n",
       "0                                       Dinosaur Planet\n",
       "28                                              Boycott\n",
       "4                              The Rise and Fall of ECW\n",
       "9                                               Fighter\n",
       "Name: movie_id, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_10(2621442)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So is the system we built any good? We can check this at least somewhat by checking if the embeddings are good. This is how we'll do it: \n",
    "1. Extract the embeddings of the different movies from the network. How, you may ask? I hope you remembered to use the functional api. This will allow you to create a new model - using the trained layers that you already used. Create a new Model where the input is the movie_id, and the output is the movie embedding layer (before the merge).\n",
    "2. Do not train this model. Only use the .predict of this model, and the output should be the embedding vectors which represent the different movie id's. Notice you may have to reshape the matrix of the predictions for the next steps.\n",
    "3. Now use sklearn.cluster.KMeans to cluster these vectors. Use k=1000. Make sure to save the cluster number for each movie.\n",
    "4. Check manually if the clusters make sense (can you find connections between movies in the same cluster?). \n",
    "5. Try to visualize the clustering by looking at only some of the clusters as one time. You can use PCA with n_components = 2 to help you visualize (use a different color for each cluster by using 'c = ...' in plt.scatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embedding = Model(inputs = [x_movie], outputs = [embedding_movie])\n",
    "\n",
    "movies_for_pred = np.array(X_test['movie_id_transformed'])\n",
    "vectors = model_embedding.predict(movies_for_pred).reshape(-1,1)\n",
    "vectors = vectors.reshape(-1,movie_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clf = KMeans(n_clusters=500)\n",
    "clusters = clf.fit_predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "clusters_1 = clusters == 1\n",
    "print(np.sum(clusters_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "clusters_2 = clusters == 2\n",
    "print(np.sum(clusters_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "clusters_3 = clusters == 3\n",
    "print(np.sum(clusters_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_1_2 = clusters_1 + clusters_2 + clusters_3\n",
    "\n",
    "vectors_chosen = vectors[clusters_1_2]\n",
    "pca = PCA(n_components = 2)\n",
    "pcaed_vectored = pca.fit_transform(vectors_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258, 20)\n"
     ]
    }
   ],
   "source": [
    "print(vectors_chosen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = clusters_1 + 2*clusters_2 + 3*clusters_3\n",
    "colors = colors[colors != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pcaed_vectored[:,0], pcaed_vectored[:,1], c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lara Croft: Tomb Raider: The Cradle of Life'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_dict[X_test.movie_id.to_numpy()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission: Impossible II\n",
      "Judge Dredd\n",
      "Murder By Numbers\n",
      "The Last American Virgin\n",
      "Mission: Impossible II\n",
      "Judge Dredd\n",
      "Friday\n",
      "Poirot: Lord Edgware Dies\n",
      "La Belle Noiseuse\n",
      "Poirot: Death in the Clouds\n",
      "Southern Comfort\n",
      "La Belle Noiseuse\n",
      "Friday\n",
      "Mission: Impossible II\n",
      "Friday\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Murder By Numbers\n",
      "Whatever It Takes\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Friday\n",
      "Murder By Numbers\n",
      "Murder By Numbers\n",
      "Godzilla vs. Mechagodzilla\n",
      "Murder By Numbers\n",
      "Mission: Impossible II\n",
      "Don Juan De Marco\n",
      "Just One of the Guys\n",
      "Friday\n",
      "Quicksand\n",
      "Murder By Numbers\n",
      "Don Juan De Marco\n",
      "Carnage\n",
      "Murder By Numbers\n",
      "The Beastmaster\n",
      "Murder By Numbers\n",
      "Judge Dredd\n",
      "The Beastmaster\n",
      "Mission: Impossible II\n",
      "Red Heat\n",
      "The Girl\n",
      "Friday\n",
      "Airport '77 / The Concorde: Airport '79: Double Feature\n",
      "Mission: Impossible II\n",
      "Mission: Impossible II\n",
      "Mission: Impossible II\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Live From Baghdad\n",
      "Don Juan De Marco\n",
      "Murder By Numbers\n",
      "Disorganized Crime\n",
      "Vampire in Brooklyn\n",
      "Mission: Impossible II\n",
      "Friday\n",
      "Friday\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Murder By Numbers\n",
      "Bionicle: Mask of Light: The Movie\n",
      "Friday\n",
      "Friday\n",
      "Murder By Numbers\n",
      "Friday\n",
      "Murder By Numbers\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "A Man Called Horse\n",
      "Friday\n",
      "The Work of Director Michel Gondry\n",
      "Mission: Impossible II\n",
      "Friday\n",
      "Mission: Impossible II\n",
      "Friday\n",
      "Murder By Numbers\n",
      "Judge Dredd\n",
      "Murder By Numbers\n",
      "Poirot: Death in the Clouds\n",
      "Friday\n",
      "Ren & Stimpy: Season 3 and a Half-ish\n",
      "The Beastmaster\n",
      "Friday\n",
      "Friday\n",
      "Murder By Numbers\n",
      "Friday\n",
      "The Jungle Book\n",
      "Norma Jean & Marilyn\n",
      "A Man Called Horse\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Live From Baghdad\n",
      "Mission: Impossible II\n",
      "Whatever It Takes\n",
      "Mission: Impossible II\n",
      "Murder By Numbers\n",
      "Murder By Numbers\n"
     ]
    }
   ],
   "source": [
    "for movie_id in X_test.movie_id.to_numpy()[clusters == 100]:\n",
    "    print(movies_dict[movie_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! Now just one little sophistication. \n",
    "Write another function which gives me the top 10 movies while no 2 of them are from the same cluster. This can be used for a more sophisticated type of recommendation system.\n",
    "\n",
    "This will be more exciting if you go back and reduce the amount of clusters you allow to be not much higher than 10 (and check how the previous system you created will react)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_transformed_to_cluster = dict(zip(movies_for_pred, clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unique = list(set(df.user_id))\n",
    "transforming_user = {v:k for k,v in zip(range(len(list_unique)), list_unique)}\n",
    "list_unique = list(set(df.movie_id))\n",
    "transforming_movie = {v:k for k,v in zip(range(len(list_unique)), list_unique)}\n",
    "\n",
    "untransforming_movie = {v: k for k, v in transforming_movie.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_10(user):\n",
    "    recommend_df = pd.DataFrame(list(set(X_test.movie_id_transformed)), \n",
    "                                columns = ['movie_id_transformed'])\n",
    "    recommend_df['user_id_transformed'] = [transforming_user[user]] * len(recommend_df)\n",
    "    recommend_df['predictions'] = model.predict([recommend_df['user_id_transformed'], \n",
    "                                                 recommend_df['movie_id_transformed']])\n",
    "    \n",
    "    top_10 = recommend_df.sort_values('predictions', ascending = False).head(10)\n",
    "    top_10['movie_id'] = top_10.movie_id_transformed.apply(lambda x: untransforming_movie[x])\n",
    "    \n",
    "    return top_10.movie_id.apply(lambda x: movies_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_10_from_different_clusters(user):\n",
    "    recommend_df = pd.DataFrame(list(set(X_test.movie_id_transformed)), \n",
    "                                columns = ['movie_id_transformed'])\n",
    "    recommend_df['user_id_transformed'] = [transforming_user[user]] * len(recommend_df)\n",
    "    \n",
    "    recommend_df['predictions'] = model.predict([recommend_df['user_id_transformed'], \n",
    "                                                 recommend_df['movie_id_transformed']])\n",
    "    \n",
    "    recommend_df['cluster'] = recommend_df.movie_id_transformed.apply(lambda x: \n",
    "                                                                      movie_id_transformed_to_cluster[x])\n",
    "\n",
    "    top_10 = recommend_df.sort_values('predictions', \n",
    "                                      ascending = False).groupby('cluster').head(1).head(10)\n",
    "    \n",
    "    top_10['movie_id'] = top_10.movie_id_transformed.apply(lambda x: untransforming_movie[x])\n",
    "    \n",
    "    return top_10.movie_id.apply(lambda x: movies_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2331    Lord of the Rings: The Two Towers: Extended Ed...\n",
       "4775            The Shawshank Redemption: Special Edition\n",
       "4911    Lord of the Rings: The Return of the King: Ext...\n",
       "4031                                        The Godfather\n",
       "4481                                            Toy Story\n",
       "3311                              Raiders of the Lost Ark\n",
       "63                             Chappelle's Show: Season 1\n",
       "4693                               The Sopranos: Season 2\n",
       "4208                                The X-Files: Season 1\n",
       "2085                                 Millennium: Season 1\n",
       "Name: movie_id, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_10_from_different_clusters(2621442)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These cells should be used for telling yourself when your code finishes running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from MMMUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep()\n",
    "\n",
    "body = 'Yo Phil, my man - your code (embedding layer exercise) finished running at: ' + str(datetime.datetime.now()) \\\n",
    "    + '\\n\\n\\nThis was an automated email'\n",
    "send_email('ptannor@gmail.com', body = body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
