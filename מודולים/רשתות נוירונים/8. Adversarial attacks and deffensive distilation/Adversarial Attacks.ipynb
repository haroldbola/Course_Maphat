{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will focus on some basic Adversarial Attack methods - Fast Gradient Sign Method (FGSM), Targeted Gradient Sign Method (TGSM), Basic Iterative Method (BIM) & Projected Gradient Descent (PGD). Before starting make sure that you feel comfortable with the basic concept of adversarial examples for classification models, and that you have a good understanding of the 4 methods. Your tutor may ask you questions about them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQEZETPDG0rq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4g14QXanG0rx"
   },
   "source": [
    "--- Create and Train a Simple MNIST CNN Classifier --- for those of you less familiar with tensorflow and keras, this is an opportunity (notice that we are using the keras API from within tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwU6OYREG0rz"
   },
   "outputs": [],
   "source": [
    "''' Build a simple MNIST classification CNN\n",
    "    The network takes ~3 minutes to train on a normal laptop and reaches roughly 97% of accuracy\n",
    "    Model structure: Conv, Conv, Max pooling, Dropout, Dense, Dense\n",
    "'''\n",
    "def build_mnist_model():\n",
    "    \n",
    "    activation = 'relu'\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols, img_colors = 28, 28, 1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(8, kernel_size=(3, 3), input_shape=(img_rows, img_cols, img_colors), activation=activation))\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation=activation))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation('softmax', name='y_pred'))\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzdMl1BRG0r3"
   },
   "outputs": [],
   "source": [
    "''' Normalize input to the range of [0..1]\n",
    "    Apart from assisting in the convergance of the training process, this \n",
    "    will also make our lives easier during the adversarial attack process\n",
    "'''\n",
    "def normalize(x_train,x_test):\n",
    "    x_train -= x_train.min()\n",
    "    x_train /= x_train.max()\n",
    "    x_test -= x_test.min()\n",
    "    x_test /= x_test.max()\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4HrIXRyG0r7"
   },
   "outputs": [],
   "source": [
    "# Load and prepare the datasets for training\n",
    "num_classes = 10\n",
    "\n",
    "img_rows, img_cols, img_colors = 28, 28, 1\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "train_images, test_images = normalize(train_images, test_images)\n",
    "    \n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the classifier might take a few minutes to train but should reach quite a high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdGg0FJsG0r_"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 128\n",
    "maxepoches = 12\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "model = build_mnist_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=maxepoches,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJhAkLskG0sE"
   },
   "outputs": [],
   "source": [
    "''' A simple utility funcion for evaluating the success of an attack\n",
    "'''\n",
    "def TestAttack(model, adv_images, orig_images, true_labels, target_labels=None, targeted=False):\n",
    "    score = model.evaluate(adv_images, true_labels, verbose=0)\n",
    "    print('Test loss: {:.2f}'.format(score[0]))\n",
    "    print('Successfully moved out of source class: {:.2f}'.format( 1 - score[1]))\n",
    "    \n",
    "    if targeted:\n",
    "        score = model.evaluate(adv_images, target, verbose=0)\n",
    "        print('Test loss: {:.2f}'.format(score[0]))\n",
    "        print('Successfully perturbed to target class: {:.2f}'.format(score[1]))\n",
    "    \n",
    "    dist = np.mean(np.sqrt(np.mean(np.square(adv_images - orig_images), axis=(1,2,3))))\n",
    "    print('Mean perturbation distance: {:.2f}'.format(dist))\n",
    "    \n",
    "    index = 10\n",
    "    img = adv_images[index].reshape(28, 28)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u71zcvGqG0sC"
   },
   "source": [
    "--- Fast Gradient Sign Method (FGSM) --- here FGSM is implemented for you as an example, make sure you understand the code, in particular look at the functions keras.backend.function and keras.backend.gradients\n",
    "\n",
    "** the solution will also include a more efficient pure tensorflow implementation but you are welcome, to use this approach for your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UY-DDb8EG0sI"
   },
   "outputs": [],
   "source": [
    "''' Fast Gradient Sign Method implementation - perturb all input features by an epsilon sized step in \n",
    "    the direction of loss gradient\n",
    "'''\n",
    "def FastGradientSignMethod(model, images, labels, epsilon=0.3):\n",
    "    true_label_tensor = keras.backend.placeholder(shape=(None, num_classes))\n",
    "    adv_loss = keras.losses.categorical_crossentropy(true_label_tensor, model.output)\n",
    "    get_grads = keras.backend.function([model.input, true_label_tensor], keras.backend.gradients(adv_loss, model.input))\n",
    "    \n",
    "    adv_grads = get_grads([images, labels])[0]\n",
    "    \n",
    "    adv_out = images + epsilon * np.sign(adv_grads)\n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test out the attack, play around with the parameters and see how they influence the result visually and regarding the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHfFFdSqG0sL"
   },
   "outputs": [],
   "source": [
    "adv_images = FastGradientSignMethod(model, test_images, test_labels, epsilon=0.3)\n",
    "TestAttack(model, adv_images, test_images, test_labels, targeted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jkg_fY7CG0sO"
   },
   "source": [
    "--- Targeted Gradient Sign Method (TGSM) --- implement this method and test out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6YNckVZKG0sR"
   },
   "outputs": [],
   "source": [
    "''' Targeted Gradient Sign Method implementation - A targeted variant of the FGSM attack\n",
    "    here we minimize the loss with respect to the target class, as opposed to maximizing the loss with respect\n",
    "    to the source class\n",
    "'''\n",
    "def TargetedGradientSignMethod(model, images, target, epsilon=0.3):\n",
    "    # TODO: Your code comes here\n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZLThCUWG0sU"
   },
   "outputs": [],
   "source": [
    "target = (np.argmax(test_labels, axis=1) + np.random.randint(1, num_classes, size=(test_labels.shape[0]))) % num_classes\n",
    "target = keras.utils.to_categorical(target, num_classes)\n",
    "adv_images = TargetedGradientSignMethod(model, test_images, target, epsilon=0.3)\n",
    "TestAttack(model, adv_images, test_images, test_labels, target, targeted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awH61CD3G0sY"
   },
   "source": [
    "--- Basic Iterative Method (BIM) --- implement this method which is the iterative upgrade to any of the two previous attacks, like before test the attack out and play around with the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abLag2V2G0sZ"
   },
   "outputs": [],
   "source": [
    "def BasicIterativeMethod(model, images, labels, epsilon=0.1, iter_eps = 0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False):\n",
    "    \n",
    "    # TODO: Your code comes here\n",
    "    \n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g02Rq0o3G0sc"
   },
   "outputs": [],
   "source": [
    "target = (np.argmax(test_labels, axis=1) + np.random.randint(1, num_classes, size=(test_labels.shape[0]))) % num_classes\n",
    "target = keras.utils.to_categorical(target, num_classes)\n",
    "adv_images = BasicIterativeMethod(model, test_images, target, iterations = 30, epsilon=4.0, iter_eps=0.05, targeted=True)\n",
    "TestAttack(model, adv_images, test_images, test_labels, target, targeted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Projected Gradient Descent (PGD) --- implement this improvement on the BIM basic variant, as usual test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after you finish the exercise make sure you look at the solutions, they include the TensorFlow only implementation which is more computationally efficient (but more complex to write), and the Cleverhans implementation which is a well known library for Adversarial Machine Learning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BIM Re-implementation Part I.ipynb",
   "provenance": [
    {
     "file_id": "1Dvp6LXt6xBbNgdHXLi8mqpz9CUqk08pP",
     "timestamp": 1585681256117
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
