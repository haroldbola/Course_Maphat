{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Anomaly detection exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIiKfQIxwGCK"
      },
      "source": [
        "## Unsupervised Anomaly Detection\n",
        "```In this exercise you will use concepts you know, and maybe some concepts you are about to meet, in order to find anomalies in dataset of credit cards transactions.\n",
        "We will think about this problem as one think of real anomaly detecting problems: your goal will be to choose the 1,000 most anomalous samples from the dataset - the samples you suspect to be the anomaly samples. In real life problems, those samples will be handed to a human researcher for verification. Obviously, if you give him a lot of regular samples, he will get angry.```\n",
        "\n",
        "```~Ittai Haran```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Y_o-S0-wwGCM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3McB7JOHwGCN"
      },
      "source": [
        "```Load the dataset. You can see it's labeled: It's for allowing you to test yourself. Note that in real life problems, you won't have it. Normalize the dataset as you see fit.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "MDZXcKahwXgL",
        "outputId": "3ab1b274-26a7-497f-8f1c-d072cca22cc1"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12246b88-a5f4-4e16-8a9f-64540918e5de\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12246b88-a5f4-4e16-8a9f-64540918e5de\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving creditcard.csv to creditcard.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "N70zwrL9wGCN",
        "outputId": "c447e254-3f23-49e6-c786-dc978f5e542d"
      },
      "source": [
        "df = pd.read_csv('creditcard.csv') ## can be found in: https://drive.google.com/open?id=1wyz2czVFaQWdqRmLAtT5MwCOSlnZ6od9\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3        V4  ...       V26       V27       V28  Class\n",
              "0 -1.359807 -0.072781  2.536347  1.378155  ... -0.189115  0.133558 -0.021053      0\n",
              "1  1.191857  0.266151  0.166480  0.448154  ...  0.125895 -0.008983  0.014724      0\n",
              "2 -1.358354 -1.340163  1.773209  0.379780  ... -0.139097 -0.055353 -0.059752      0\n",
              "3 -0.966272 -0.185226  1.792993 -0.863291  ... -0.221929  0.062723  0.061458      0\n",
              "4 -1.158233  0.877737  1.548718  0.403034  ...  0.502292  0.219422  0.215153      0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-diS-QIwGCN",
        "outputId": "cffc3b9f-45f6-4a95-e244-8d222ec6d1ed"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "label = df['Class']\r\n",
        "\r\n",
        "data = df.drop(columns=[\"Class\"])\r\n",
        "data = pd.DataFrame(MinMaxScaler().fit_transform(data))\r\n",
        "data = data.to_numpy()\r\n",
        "\r\n",
        "print(\"data\", data.shape)\r\n",
        "print(\"label\", label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data (284807, 28)\n",
            "label (284807,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shj2DkmRwGCN"
      },
      "source": [
        "```Your first task is to formulate a method for evaluating your anomalies. Write an evaluation method, which will help you compare between different ways to detect anomalies. Notice that this isn't a classification method, and regard your true goal: to mark the 1,000 most anomalous samples.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5k1zI8lKwGCO"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def evaluate_method(y_true, grades):\n",
        "    # y_true is the class: 0 for regular, 1 for anomaly\n",
        "    # the grades should indicate how anomalous you think the sample is - as higher the grade, the sample is more suspiciuos\n",
        "    indices_higher_grades = np.argsort(grades)[:-1000]\n",
        "    return roc_auc_score(y_true[indices_higher_grades], grades[indices_higher_grades])\n",
        "\n",
        "all_grades = np.zeros(shape=(data.shape[0], 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjWkYN6JwGCO"
      },
      "source": [
        "```We can now examine different methods for anomaly detecting. For each method, evaluate it, and compare it to the other methods.```\n",
        "\n",
        "```The first one we will try is to grade the samples by their distance from the 'mean sample', in units of standard deviation. You can also think about the features as independent gaussian distributions and grade a sample by its distance from the gaussian's mean, for every feature.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXSFl-powGCO",
        "outputId": "cc60b429-3480-4502-dc3e-bd9745da9aee"
      },
      "source": [
        "data_mean = data.mean(axis=0)\r\n",
        "data_std = data.std(axis=0)\r\n",
        "distances = np.sum(np.abs(data - data_mean) / data_std, axis=1)\r\n",
        "\r\n",
        "all_grades[:, 0] = distances\r\n",
        "print(evaluate_method(label, distances))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9228197343854639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu92inHcwGCP"
      },
      "source": [
        "```What hidden assumption you took during \"training\"? what part of the data you trained on?```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gjF3BzplwGCP",
        "outputId": "7edf4068-ab06-466a-8d19-31818fa02217"
      },
      "source": [
        "\"\"\"\r\n",
        "I trained on all the data available (284807 samples). As I didnt use the labels, the is no leakage of information.\r\n",
        "The hidden assumption is that the majority of the samples are not anomalies, and then then 'mean sample' would represent in a good way the normal credit card transactions.\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nI trained on all the data available (284807 samples). As I didnt use the labels, the is no leakage of information.\\nThe hidden assumption is that the majority of the samples are not anomalies, and then then 'mean sample' would represent in a good way the normal credit card transactions.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifHoW0sOwGCP"
      },
      "source": [
        "```Try using PCA: project the dataset into a lower dimensional space, and than use the \"inverse\" transformation (why \"\"?) to get approximated samples. Compare the samples you got to the samples you started with.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05n-hKXLwGCP",
        "outputId": "af019722-1b82-4636-fdae-6f6edf3dd525"
      },
      "source": [
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "pca_model = PCA(15)\r\n",
        "pca_model.fit(data)\r\n",
        "\r\n",
        "reconstruct_data = pca_model.inverse_transform(pca_model.transform(data))\r\n",
        "distances_PCA = np.sum(np.abs(data - reconstruct_data), axis=1)\r\n",
        "\r\n",
        "all_grades[:, 1] = distances_PCA\r\n",
        "print(evaluate_method(label, distances_PCA))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9159451148290565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhqznUVZwGCP"
      },
      "source": [
        "```Read about one class SVM. Use it to evaluate your samples. Notice that this algorithm is very slow compared to those you tried earlier. Consider training it only on a fraction of the samples.\n",
        "Hint: you can use the decision function directly to get the distance of the sample from the decision boundary.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAu79fa9wGCQ",
        "outputId": "61a99dfb-2f38-4baa-dd52-c0758e971c56"
      },
      "source": [
        "from sklearn.svm import OneClassSVM\r\n",
        "\r\n",
        "svm_model = OneClassSVM(gamma='auto', verbose=True)\r\n",
        "svm_model.fit(data[0:100000,:])\r\n",
        "\r\n",
        "decisions = svm_model.decision_function(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbzahyusGrlI",
        "outputId": "44abff43-f763-40f7-895d-8e53c8c6a1b7"
      },
      "source": [
        "decisions = -decisions\r\n",
        "decisions[decisions<0] = 0\r\n",
        "\r\n",
        "all_grades[:, 2] = decisions\r\n",
        "print(evaluate_method(label, decisions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8657004587518036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB6iG285wGCQ"
      },
      "source": [
        "```Now try clustering your data, and use the distance from the clusters (you will have to define it) to grade the samples. Think about changing your normalization method when trying to cluster. Here you also might want to consider to train on a fraction of the samples.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KijZh39rG8Fe",
        "outputId": "e13db4dc-591e-4a1d-8a1a-f4d7721fb873"
      },
      "source": [
        "from sklearn.cluster import KMeans\r\n",
        "from numpy.linalg import norm\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "def clustering(nb_cluster):\r\n",
        "  kmeans_model = KMeans(nb_cluster, n_jobs = -1)\r\n",
        "  kmeans_model.fit(data[:100000])\r\n",
        "\r\n",
        "  centers_clusters = kmeans_model.cluster_centers_\r\n",
        "\r\n",
        "  grades = np.zeros(shape=data.shape[0])\r\n",
        "  for i in tqdm(range(data.shape[0])):\r\n",
        "    distance_closest_cluster = norm(data[i]-centers_clusters, axis=1)\r\n",
        "    grades[i] = np.min(distance_closest_cluster)\r\n",
        "\r\n",
        "  if nb_cluster==10:\r\n",
        "    all_grades[:, 3] = grades\r\n",
        "  print(\"for \", nb_cluster, \"clusters, roc=\", evaluate_method(label, grades))\r\n",
        "\r\n",
        "clustering(nb_cluster=2)\r\n",
        "clustering(nb_cluster=10)\r\n",
        "clustering(nb_cluster=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 284807/284807 [00:06<00:00, 43545.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "for  2 clusters, roc= 0.8726944576139956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 284807/284807 [00:07<00:00, 37421.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "for  10 clusters, roc= 0.9182799531361588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 284807/284807 [00:04<00:00, 66904.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "for  20 clusters, roc= 0.9168329281468247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "dewYRSujwGCQ"
      },
      "source": [
        "```Try combining the grades you got from different methods into a single grade. Did you get a better detector? why or why not?```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZa3xVNJwGCR",
        "outputId": "ef1ce19f-3244-4696-811b-3b324e4712f3"
      },
      "source": [
        "from sklearn.mixture import GaussianMixture\r\n",
        "\r\n",
        "clf_gaussian = GaussianMixture(n_components=10)\r\n",
        "clf_gaussian.fit(all_grades)\r\n",
        "\r\n",
        "centers_clusters = clf_gaussian.means_\r\n",
        "\r\n",
        "final_grade = np.zeros(shape=all_grades.shape[0])\r\n",
        "for i in tqdm(range(all_grades.shape[0])):\r\n",
        "  distance_closest_cluster = norm(all_grades[i]-centers_clusters, axis=1)\r\n",
        "  final_grade[i] = np.min(distance_closest_cluster)\r\n",
        "\r\n",
        "print(evaluate_method(label, final_grade))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 284807/284807 [00:06<00:00, 42036.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8594277689633578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQFoP-HbwGCR"
      },
      "source": [
        "```Now we will experience with Deep Auto Encoders. The idea is to create a neural network that gets the samples as input, and try to predict the very same samples: The difficulty comes from the fact that the networks gets narrower, and so having an information bottleneck. The grade each sample will get is the reconstruction error - the difference between the output and the input. You can read more about Auto Encoders in the literature.\n",
        "(If you want to know more about Auto Encoders, read also about about Variational Auto Encoder)```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1GDhbD7vwGCR"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.activations import exponential\n",
        "from keras.initializers import RandomNormal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "I0bMvb9PwGCR"
      },
      "source": [
        "class VAE(tf.keras.Model):\r\n",
        "\r\n",
        "    def __init__(self, input_size):\r\n",
        "        super(VAE, self).__init__()\r\n",
        "\r\n",
        "        self.encoder = Sequential()\r\n",
        "        self.encoder.add(Input((input_size)))\r\n",
        "        self.encoder.add(Dense((input_size*0.8), activation='tanh'))\r\n",
        "        self.encoder.add(Dense((input_size*0.6), activation='tanh'))\r\n",
        "        self.encoder.add(Dense((input_size*0.4), activation='tanh'))\r\n",
        "        self.encoder.add(Dense((input_size*0.2), activation='tanh'))\r\n",
        "\r\n",
        "        self.decoder = Sequential()\r\n",
        "        self.decoder.add(Dense((input_size*0.2), activation='tanh'))\r\n",
        "        self.decoder.add(Dense((input_size*0.4), activation='tanh'))\r\n",
        "        self.decoder.add(Dense((input_size*0.6), activation='tanh'))\r\n",
        "        self.decoder.add(Dense((input_size*0.8), activation='tanh'))\r\n",
        "        self.decoder.add(Dense((input_size), activation='sigmoid'))\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "      h = self.encoder(inputs)\r\n",
        "      inputs_recon = self.decoder(h)\r\n",
        "      return inputs_recon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDdHpfHiO5kQ",
        "outputId": "1cc87731-c167-4f97-f151-2175ae222750"
      },
      "source": [
        "model = VAE(input_size=28)\r\n",
        "model.compile(optimizer='rmsprop', loss =\"mse\")\r\n",
        "\r\n",
        "label = df['Class']\r\n",
        "\r\n",
        "data = df.drop(columns=[\"Class\"])\r\n",
        "model.fit(data, data, batch_size=500, epochs=20, verbose=2)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "570/570 - 2s - loss: 1.0369\n",
            "Epoch 2/20\n",
            "570/570 - 2s - loss: 0.9553\n",
            "Epoch 3/20\n",
            "570/570 - 2s - loss: 0.9405\n",
            "Epoch 4/20\n",
            "570/570 - 2s - loss: 0.9340\n",
            "Epoch 5/20\n",
            "570/570 - 2s - loss: 0.9300\n",
            "Epoch 6/20\n",
            "570/570 - 2s - loss: 0.9244\n",
            "Epoch 7/20\n",
            "570/570 - 2s - loss: 0.9202\n",
            "Epoch 8/20\n",
            "570/570 - 2s - loss: 0.9171\n",
            "Epoch 9/20\n",
            "570/570 - 2s - loss: 0.9132\n",
            "Epoch 10/20\n",
            "570/570 - 2s - loss: 0.9090\n",
            "Epoch 11/20\n",
            "570/570 - 2s - loss: 0.9055\n",
            "Epoch 12/20\n",
            "570/570 - 2s - loss: 0.9030\n",
            "Epoch 13/20\n",
            "570/570 - 2s - loss: 0.9007\n",
            "Epoch 14/20\n",
            "570/570 - 2s - loss: 0.8987\n",
            "Epoch 15/20\n",
            "570/570 - 2s - loss: 0.8967\n",
            "Epoch 16/20\n",
            "570/570 - 2s - loss: 0.8945\n",
            "Epoch 17/20\n",
            "570/570 - 2s - loss: 0.8922\n",
            "Epoch 18/20\n",
            "570/570 - 2s - loss: 0.8903\n",
            "Epoch 19/20\n",
            "570/570 - 2s - loss: 0.8889\n",
            "Epoch 20/20\n",
            "570/570 - 2s - loss: 0.8876\n",
            "Model: \"vae_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_7 (Sequential)    (None, 5)                 1253      \n",
            "_________________________________________________________________\n",
            "sequential_8 (Sequential)    (None, 28)                1306      \n",
            "=================================================================\n",
            "Total params: 2,559\n",
            "Trainable params: 2,559\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C-MeJRBPYcp",
        "outputId": "7648d14e-735f-4f02-b53e-5220be92a8bc"
      },
      "source": [
        "VAE_grades = np.linalg.norm(model.predict(data, batch_size=500)-data, axis = 1)\r\n",
        "evaluate_method(label, VAE_grades)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9241341865651618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irVK7g4lwGCS"
      },
      "source": [
        "## Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS1s7enYwGCS"
      },
      "source": [
        "```Try thinking about other methods to detect anomalies in your data, and find a way to get better results.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vn0qHEcwGCS",
        "outputId": "ded55e4d-d18d-45ce-a285-2d56d7a6715d"
      },
      "source": [
        "from sklearn.cluster import SpectralClustering\r\n",
        "\r\n",
        "def spectral_clustering(nb_cluster):\r\n",
        "  kmeans_model = SpectralClustering(nb_cluster, n_jobs = 3)\r\n",
        "  kmeans_model.fit(data[:10000])\r\n",
        "\r\n",
        "  affinity_matrix = kmeans_model.affinity_matrix_\r\n",
        "\r\n",
        "  grades = 1 / np.linalg.norm(affinity_matrix, axis=0)\r\n",
        "  print(\"for \", nb_cluster, \"clusters, roc=\", evaluate_method(label, grades))\r\n",
        "\r\n",
        "spectral_clustering(nb_cluster=2)\r\n",
        "spectral_clustering(nb_cluster=10)\r\n",
        "spectral_clustering(nb_cluster=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01109431 0.0107819  0.01162391 ... 0.01093071 0.01085852 0.01121639]\n",
            "for  2 clusters, roc= 0.8978775419491054\n",
            "[0.01109431 0.0107819  0.01162391 ... 0.01093071 0.01085852 0.01121639]\n",
            "for  10 clusters, roc= 0.8978775419491054\n",
            "[0.01109431 0.0107819  0.01162391 ... 0.01093071 0.01085852 0.01121639]\n",
            "for  20 clusters, roc= 0.8978775419491054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P_FUeXyDV2o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}